{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchinfo\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import sympy as sp\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.metrics import r2_score,mean_squared_error,confusion_matrix\n",
    "from sklearn.ensemble import BaggingClassifier,BaggingRegressor,RandomForestClassifier,RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from nltk import sent_tokenize\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import silhouette_score\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier,AdaBoostClassifier,AdaBoostRegressor,GradientBoostingClassifier,GradientBoostingClassifier\n",
    "#from xgboost import XGBClassifier,XGBRegressor,XGBRFRegressor,XGBRFClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,r2_score,classification_report,confusion_matrix,precision_score,recall_score,f1_score\n",
    "from sklearn.datasets import make_regression,make_classification\n",
    "from sklearn.linear_model import SGDRegressor,SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,LabelEncoder,OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_selection import VarianceThreshold \n",
    "from sklearn.feature_selection import SelectKBest,chi2 ,SelectPercentile,f_classif,mutual_info_classif,VarianceThreshold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.dummy import DummyClassifier,DummyRegressor\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#from imblearn.ensemble import BalancedRandomForestClassifier,BalancedBaggingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "import statsmodels.api as sm\n",
    "import sympy as sp\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import BaggingClassifier,BaggingRegressor,RandomForestClassifier,RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression,SGDRegressor,SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier,AdaBoostClassifier,AdaBoostRegressor,GradientBoostingClassifier,GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier,XGBRegressor \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,r2_score,classification_report,confusion_matrix\n",
    "from sklearn.datasets import make_regression,make_classification\n",
    "from sklearn.linear_model import SGDRegressor,SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,LabelEncoder,OrdinalEncoder,Normalizer,MinMaxScaler,OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_selection import SelectPercentile,SelectKBest,chi2,f_classif,mutual_info_regression,mutual_info_classif,VarianceThreshold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.datasets import load_diabetes,load_breast_cancer,load_iris\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer,SnowballStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.ensemble import StackingClassifier,StackingRegressor\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Correct way to ignore warnings\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective : To classify the text from multiple images which are grouped under multiple classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 500 files\n",
      "Class 2: 500 files\n",
      "Class 4: 500 files\n",
      "Class 6: 500 files\n",
      "Class 9: 500 files\n"
     ]
    }
   ],
   "source": [
    "# read the files containing the text\n",
    "import os\n",
    "\n",
    "def read_and_group_data(root_folder):\n",
    "    \"\"\"\n",
    "    Reads text files from subfolders within a root folder.\n",
    "    Groups files by folder name (class label).\n",
    "    \n",
    "    Args:\n",
    "        root_folder (str): Path to the root folder containing subfolders.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Keys are class labels (folder names), values are lists of file contents.\n",
    "    \"\"\"\n",
    "    grouped_data = {}  # Dictionary to hold class-wise grouped data\n",
    "    \n",
    "    # Iterate through all folders in the root folder\n",
    "    for class_folder in os.listdir(root_folder):\n",
    "        class_path = os.path.join(root_folder, class_folder)\n",
    "        \n",
    "        # Check if the item is a folder (class label)\n",
    "        if os.path.isdir(class_path):\n",
    "            grouped_data[class_folder] = []  # Initialize a list for the class\n",
    "            \n",
    "            # Iterate through all text files in the folder\n",
    "            for file_name in os.listdir(class_path):\n",
    "                file_path = os.path.join(class_path, file_name)\n",
    "                \n",
    "                # Read the content of each text file\n",
    "                if file_name.endswith('.txt'):  # Ensure only .txt files are read\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        file_content = file.read()\n",
    "                        grouped_data[class_folder].append(file_content)\n",
    "    \n",
    "    return grouped_data\n",
    "\n",
    "# Example Usage\n",
    "root_folder = \"D:\\Machine_learning\\mltest\\ML\\data\\ocr\"  # Replace with your actual folder path\n",
    "data = read_and_group_data(root_folder)\n",
    "\n",
    "# Print grouped data summary\n",
    "for class_label, files in data.items():\n",
    "    print(f\"Class {class_label}: {len(files)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nAneto Pi eth Asin\\n\\n \\n\\n15 Fieerih Sie,...</td>\n",
       "      <td>2078873514\\n\\n \\n\\nOriginal Message\\nFrom: Tap...</td>\n",
       "      <td>Bias ora\\n\\nOe ant ie\\n\\nee\\n! a\\n\\nTe ea LI e...</td>\n",
       "      <td>sgaloiat\\n\\n~\\n\\nNoi nditunOs Hod,\\n\\nilodqzod...</td>\n",
       "      <td>Mar 13Â°96\\nMARS 9 1908\\n\\n8335\\n\\nMINNEAPOLIS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDs PAGE 21729\\nDrenee ve eeepeneectnmnnnne\\n\\...</td>\n",
       "      <td>\\n\\n \\n\\n&lt;&gt;\\n\\nFars em\\n\\nWORLD ALERT near\\n\\...</td>\n",
       "      <td>\\n\\n \\n    \\n\\n \\n\\n~~ TOBACC\\nRETAINS\\nRICH ...</td>\n",
       "      <td>\\n\\nGH. as The\\nie nd poologel\\n\\n \\n\\nfetabo...</td>\n",
       "      <td>200343)2394\\n\\n    \\n\\n010) asuodsax uy sour\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PHILIP MORRIS\\n\\nwor 0b, 1977\\n\\n&lt; Senet tybie...</td>\n",
       "      <td>\\n\\nLevy, Carolyn J.\\nâThursday, June 10, 199...</td>\n",
       "      <td>\\n\\n| Some straight talk\\nabout smoking\\nfor ...</td>\n",
       "      <td>MEDICAL RECORD AND ANNALS 985\\n\\nMEDICAL RECOR...</td>\n",
       "      <td>fs! 2046965323\\n\\nKateaânoag vat db 0 sea mas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gary L. Huber, M.D.\\n\\nChief, Division of Resp...</td>\n",
       "      <td>\\n\\n2084289491\\nGusato, Denise\\n\\nCusato, Den...</td>\n",
       "      <td>\\n\\nâSURGEON GENERAL'S WARNING: Cigerette\\nâS...</td>\n",
       "      <td>\\n\\nPAIN Ay i) 2) 2) 2) EP 7) 7) TEED ED ENE...</td>\n",
       "      <td>\\n\\n \\n\\n \\n\\nâSUN-TIMES\\nChicago, Illinois\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE TOBACCO INSTITUTE, INC\\n1776 K Street, Nor...</td>\n",
       "      <td>\\n\\n \\n\\n20187776) page 1\\nMessage. for Holle...</td>\n",
       "      <td>\\n\\n \\n\\noozze\\nBuIL\\n\\nung\\n\\n  \\n\\n311a/ ON...</td>\n",
       "      <td>\\n\\npene 20 paces sian (09 pow 0: âaang 79 ...</td>\n",
       "      <td>\\n\\nâ ROAZ7IOZ 7\\n\\nPage 4\\nAmerican Medical ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0   \\n\\nAneto Pi eth Asin\\n\\n \\n\\n15 Fieerih Sie,...   \n",
       "1  IDs PAGE 21729\\nDrenee ve eeepeneectnmnnnne\\n\\...   \n",
       "2  PHILIP MORRIS\\n\\nwor 0b, 1977\\n\\n< Senet tybie...   \n",
       "3  Gary L. Huber, M.D.\\n\\nChief, Division of Resp...   \n",
       "4  THE TOBACCO INSTITUTE, INC\\n1776 K Street, Nor...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  2078873514\\n\\n \\n\\nOriginal Message\\nFrom: Tap...   \n",
       "1   \\n\\n \\n\\n<>\\n\\nFars em\\n\\nWORLD ALERT near\\n\\...   \n",
       "2   \\n\\nLevy, Carolyn J.\\nâThursday, June 10, 199...   \n",
       "3   \\n\\n2084289491\\nGusato, Denise\\n\\nCusato, Den...   \n",
       "4   \\n\\n \\n\\n20187776) page 1\\nMessage. for Holle...   \n",
       "\n",
       "                                                   4  \\\n",
       "0  Bias ora\\n\\nOe ant ie\\n\\nee\\n! a\\n\\nTe ea LI e...   \n",
       "1   \\n\\n \\n    \\n\\n \\n\\n~~ TOBACC\\nRETAINS\\nRICH ...   \n",
       "2   \\n\\n| Some straight talk\\nabout smoking\\nfor ...   \n",
       "3   \\n\\nâSURGEON GENERAL'S WARNING: Cigerette\\nâS...   \n",
       "4   \\n\\n \\n\\noozze\\nBuIL\\n\\nung\\n\\n  \\n\\n311a/ ON...   \n",
       "\n",
       "                                                   6  \\\n",
       "0  sgaloiat\\n\\n~\\n\\nNoi nditunOs Hod,\\n\\nilodqzod...   \n",
       "1   \\n\\nGH. as The\\nie nd poologel\\n\\n \\n\\nfetabo...   \n",
       "2  MEDICAL RECORD AND ANNALS 985\\n\\nMEDICAL RECOR...   \n",
       "3    \\n\\nPAIN Ay i) 2) 2) 2) EP 7) 7) TEED ED ENE...   \n",
       "4     \\n\\npene 20 paces sian (09 pow 0: âaang 79 ...   \n",
       "\n",
       "                                                   9  \n",
       "0  Mar 13Â°96\\nMARS 9 1908\\n\\n8335\\n\\nMINNEAPOLIS ...  \n",
       "1  200343)2394\\n\\n    \\n\\n010) asuodsax uy sour\\n...  \n",
       "2  fs! 2046965323\\n\\nKateaânoag vat db 0 sea mas ...  \n",
       "3   \\n\\n \\n\\n \\n\\nâSUN-TIMES\\nChicago, Illinois\\n...  \n",
       "4   \\n\\nâ ROAZ7IOZ 7\\n\\nPage 4\\nAmerican Medical ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text label\n",
      "0   \\n\\nAneto Pi eth Asin\\n\\n \\n\\n15 Fieerih Sie,...     0\n",
      "1  IDs PAGE 21729\\nDrenee ve eeepeneectnmnnnne\\n\\...     0\n",
      "2  PHILIP MORRIS\\n\\nwor 0b, 1977\\n\\n< Senet tybie...     0\n",
      "3  Gary L. Huber, M.D.\\n\\nChief, Division of Resp...     0\n",
      "4  THE TOBACCO INSTITUTE, INC\\n1776 K Street, Nor...     0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_folders(root_folder):\n",
    "    \"\"\"\n",
    "    Reads text files from subfolders within a root folder and creates a DataFrame\n",
    "    with two columns: 'text' (file content) and 'label' (folder name as class label).\n",
    "    \n",
    "    Args:\n",
    "        root_folder (str): Path to the root folder containing subfolders.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with text data and corresponding labels.\n",
    "    \"\"\"\n",
    "    data = []  # List to store rows as (text, label)\n",
    "    \n",
    "    # Iterate through all folders in the root folder\n",
    "    for class_folder in os.listdir(root_folder):\n",
    "        class_path = os.path.join(root_folder, class_folder)\n",
    "        \n",
    "        # Check if the item is a folder (class label)\n",
    "        if os.path.isdir(class_path):\n",
    "            # Iterate through all text files in the folder\n",
    "            for file_name in os.listdir(class_path):\n",
    "                file_path = os.path.join(class_path, file_name)\n",
    "                \n",
    "                # Read the content of each text file\n",
    "                if file_name.endswith('.txt'):  # Ensure only .txt files are read\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        file_content = file.read()\n",
    "                        data.append((file_content, class_folder))  # Append (text, label) tuple\n",
    "    \n",
    "    # Create a DataFrame with two columns: 'text' and 'label'\n",
    "    df = pd.DataFrame(data, columns=['text', 'label'])\n",
    "    return df\n",
    "\n",
    "# Example Usage\n",
    "root_folder = \"D:\\Machine_learning\\mltest\\ML\\data\\ocr\"  # Replace with your actual folder path\n",
    "df = create_dataframe_from_folders(root_folder)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())  # Show the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nAneto Pi eth Asin\\n\\n \\n\\n15 Fieerih Sie,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDs PAGE 21729\\nDrenee ve eeepeneectnmnnnne\\n\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PHILIP MORRIS\\n\\nwor 0b, 1977\\n\\n&lt; Senet tybie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gary L. Huber, M.D.\\n\\nChief, Division of Resp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE TOBACCO INSTITUTE, INC\\n1776 K Street, Nor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0   \\n\\nAneto Pi eth Asin\\n\\n \\n\\n15 Fieerih Sie,...     0\n",
       "1  IDs PAGE 21729\\nDrenee ve eeepeneectnmnnnne\\n\\...     0\n",
       "2  PHILIP MORRIS\\n\\nwor 0b, 1977\\n\\n< Senet tybie...     0\n",
       "3  Gary L. Huber, M.D.\\n\\nChief, Division of Resp...     0\n",
       "4  THE TOBACCO INSTITUTE, INC\\n1776 K Street, Nor...     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    500\n",
       "2    500\n",
       "4    500\n",
       "6    500\n",
       "9    500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IDs PAGE 21729\\nDrenee ve eeepeneectnmnnnne\\n\\nBashingun, BC 20515\\nSeptenber 28, 1995\\n\\nâThe. Honorable William J. Clinton\\nPresident of the United States\\n\\n1600 Pennsylvania Avenue\\nWashington, D.C. 20500 =\\n\\nDear Mr. President:\\n\\nAa Republican Menbers of Congress, ve are writing to\\ninform you of our egpore fo commen geane acco sagetsttong\\naimed at curbing access. Sone have tried to paint this as a\\n\\nsan issue, Which ig clearly not true. Ne are cautious in our\\nSupport of government regulations. However, reasonable ~\\nregulations aimed at preventing cur youth from or using\\nother tobacco products are a uatter of national health.\\n\\nâThis nation can no longer close its eyes to a product\\nthat kil2e 400,000 Aericans each year and brings into its deathly\\nfold 3,000 children every day. Given the increase in\\namong and the fact that 90 percent of adult smokers started\\n\\nyouth\\nbefore 19, it is time to take the necessary ateps to prevent\\nShother genefation from becoming addicted to this deatly product.\\n\\nFurthermore, we know that people overwhelming2;\\nsmoke the three eost-advertised brands. We are aloo evare of\\nattempts by the tebacca industry to replenish their fold of\\nsmokers by spending billions of dollars in advertising targeting\\nchildren.\\nEvery independent scientific body that has reviewed the ~\\n\\nevidence now that tobacco products are addictive. These\\n\\nâthe Institute of Hedicine, U.S. of Health and\\n\\ninclude\\nHuman Services, the World Health Organization, the American\\nPsy ic Association, and the Anerican Medical Association. It\\n\\nsychiatri\\nis time for the nicotine in tobacco products to be treated 14]\\nthe highly addictive substance it is. ea xe\\n\\nTeenage guakiog {0 a national health ieque and we\\nsupport your vortiuhile efforts to improve rf\\ngenerations through reasonable regulations. * ecere\\n\\nSincerely,\\n\\nSE See\\n\\n \\n\\neL2T6Ez902\\n\\x0c'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(55), np.float64(0.022))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum(),df.duplicated().sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(0), np.float64(0.0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum(),df.duplicated().sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Preprocessing\n",
    "# Remove tags\n",
    "# lowercase\n",
    "# remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_tags(raw_text):\n",
    "    cleaned_text = re.sub(re.compile('<.*?>'), '', raw_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(remove_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\naneto pi eth asin\\n\\n \\n\\n15 fieerih sie,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ids page 21729\\ndrenee ve eeepeneectnmnnnne\\n\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>philip morris\\n\\nwor 0b, 1977\\n\\n&lt; senet tybie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gary l. huber, m.d.\\n\\nchief, division of resp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the tobacco institute, inc\\n1776 k street, nor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0   \\n\\naneto pi eth asin\\n\\n \\n\\n15 fieerih sie,...     0\n",
       "1  ids page 21729\\ndrenee ve eeepeneectnmnnnne\\n\\...     0\n",
       "2  philip morris\\n\\nwor 0b, 1977\\n\\n< senet tybie...     0\n",
       "3  gary l. huber, m.d.\\n\\nchief, division of resp...     0\n",
       "4  the tobacco institute, inc\\n1776 k street, nor...     0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw_list = stopwords.words('english')\n",
    "sw_list = stopwords.words('english')\n",
    "sw_list.remove(\"not\")  # Exclude \"not\" from stopwords\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: [item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aneto pi eth asin 15 fieerih sie, ww washing, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ids page 21729 drenee eeepeneectnmnnnne bashin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>philip morris wor 0b, 1977 &lt; senet tybieht laa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gary l. huber, m.d. chief, division resptrator...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tobacco institute, inc 1776 k street, nortthwe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  aneto pi eth asin 15 fieerih sie, ww washing, ...     0\n",
       "1  ids page 21729 drenee eeepeneectnmnnnne bashin...     0\n",
       "2  philip morris wor 0b, 1977 < senet tybieht laa...     0\n",
       "3  gary l. huber, m.d. chief, division resptrator...     0\n",
       "4  tobacco institute, inc 1776 k street, nortthwe...     0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,0:1]\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying BoW\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=75)\n",
    "X_train_bow = cv.fit_transform(X_train['text']).toarray()\n",
    "X_test_bow = cv.transform(X_test['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 4, 0, ..., 5, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], shape=(489, 75))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum word length: 75\n"
     ]
    }
   ],
   "source": [
    "max_word_length = max(len(word) for sentence in df.text for word in sentence.split())\n",
    "print(\"Maximum word length:\", max_word_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence with the maximum words: : i664 chemical. abstracts âstings remained healthy, tn 10 ebilren, jaundice ob- sting sep af ase cloves siblings andthe sgee gp ner disease sevens protracted. 1b chi gren disease nas revealed ay. oth weck fe. sree eee baieubia eiguearonige, diirubinura, and. besnatory absence bile pigments feces were, obverved, âtae lacr2ase fru transauinases aetvity wes verulsy found atienty although tin mas oot qbserved cases a8 bee ah lacase. elevated activityâ serum alk peesthatase,aldsiae, ceruloplasmin, increae choles ferre acest eccorred rather protracted cholestasis fine siferemat diagnose sgauast bile ducte atresia uiieate etiopathogenets disease fs evidently com lex. 15 gefcrences âb. talat âhoa? cetion sodiam saliylate various stages âeclopropenees rate influence certain sbifis0c- gia female oraniom opt teratogenic gti. na ses mase bieri med, leningrad). fermatel, feiss sos, aateatioor)(russ). nav eaicyate (300-600 fee) ses administered pregnant rats caused embryonal en ha deals mre ten, seats sesh sed pelvic region. enibryo senate foie conor ety alge aioe \"sock days prctaancy cap, 100 day de tetees sboerecd b54 tke fetuses,Â» paobieation gf ike ooter potestated damaging elects na salicylate, sut chlompromsuine (ue eg) injected 1b. bex aac rmblescon prevented efcets nx salicylate dhmovin, eects ne scylte intensified ad pisiation af hiiâ¬1 and: deceased nahco, indicating shae electrolyte balance mother's body afer, bealoh ee fetus, tb references, âbur 1s5Â¢\\ lysocoma injury ia marie vee depa, nary vy. datta, wallace a. jones, kurt j. inepocher, hapvacd med, souls boston, mash). gosrozitrtogy $218), 828 $0 usgiytteeh tysmwotal injury has. bees studied mice stitv'@ vas infection employing tochem. nato; eer eanes, ia animale anculated vr, anatomical shimmaisere le ccoted um pes. 2 hrs sereare ees'prospbatase activity could stowa 40% livers. srey parce ne, hae ee sgerrsst uut se ras changes progsessed 7 days 1 chen ended return normal.â early changes inthe renee pr temas secs ae ey ee iptocobual injury may play role ination pe jeti ecto following mews vial infection sapper, 1066s onidiability caringgenie bydrocarbons. ando. eset (grace hospr, det, mien.â groce hor. bul. 48 gspsllgeet dese)â oaidiablty carcinosenie ply us se iparocutne, byttbenzonyrete, 9 odie see ce sh-metipichoanthrene, la beneantirscene, ond eee sheamaneaceney det \"using. dong. omidants seorand kstage sharacterstie change ia wt srleapeioy spscrrvm ceterion anit oxide 0 spe ees te sequences oxidabilty eat. bishcenicy ndieates orn fs probably necenary ast seesst ea? development malignancy due comps. ssp rill te complenerot patymacter hy orocarbons wath ae ee enced ror light ows. ree hy droar boss. fen ars net step im carcinogenic rman 6s7ttnportance serum aldolce estinaton tn, eages ett meg tay ne ne gupte. fedion j. med. sse sis lliobieogy.. method sey lenser ta riattan sad dubowite, lancet 19041, 205), modi (mair ou! glyecaideyde fr standard, wae employed hen la diac sornal states 18 tetanus patent bebahiy senieant imerease sum, dole activity aas seeryed, winch decly proportional oe rate tlaust ike mustlur spasm.â aeomeam value 54.28 unite tpopreas found sompazed seth tae mean activity bsfo\"aaits normal adultâ patiets aldolase seit ef $0 unico 83% died weatment se aris cin cours aldlare teel occured 0 sesrstisse era ean tels comeluded thatthe serum fem sits b cxuemely wie diagnosis prownoss â *f. gordon 16684. servo lipase determination dog, waing 8 one neh, spun ges dete rnc breuer (sehotot wet ree sca. pardve uanylatayette indiana). j. amer. ve. sree ass i500), s07-71g067) eng. ins test aoe olive eee ee serum lipase {u jevel io 18 heathy dons se rocbyler quits, elevations seen 4 ops hiatth'pinercaue nccrosie produced injecting ccl \"pare wad man. concn. t24-h8 hrs. pancreatic damage. ettore âgnyase tare valuable nthe recognition acute nvinse tats tepid annvtnee elevated vol. 67, 1967 mee corte, ti elevated cote prnrete amt ba nag} seistea tanger anylave not abected byes eee strese factors rosbecs ot tote dra eyatteis ip scrple-atected mene = rim kinbenin c.d. hunter net res, animate rea nels d. geae veal al), uses os wa see a. gf oa synthase de tamer) ts sige east rege oe west ee eahe ape aent brk oars crug u elastic, | sincat scrapie, te synthesized dnas ayes - $c necenr watkin eal whereas go, pssalnlyassoed. mitochondria. âserapie-assoed. dna depressed vivo presen hes statee etter, ad ony ny fpectie iibitors dna synthesis, however, normal eves ese emu cana late tepeaed ee ta bemichepacine monsliyaronyarea terouthewt woe een ced hoe peed ofthe dcesee. \"tass, dna syntheses net yee * etabed ia development disease 27 relecsce te âsandip kuma boa 1670p_cytochemical observations om proteins, sia aa sclt woptatssee asenosiceipooopbatate, saucezce teeta cites inecled taekonweant vga st, bee snacma bm, hosigberg (uaivwof mowers 2% reahesths oy proteol. ia(t), 120400807 (eo 2 os abuse wider gncibucion aad higher intensity ance = tt [a bitin ere revealed cick ver cals reas ea. techiod tian ith, millonâ testy pretoâ om parsed cle.â coltres exper toreeon bowed prgreve depiin prin, nemevar > shovel pintooprase mete preset macrophages rome ssue feridieetdcotares, sd phosphatase treet ser eae around tne cegled ragelates. al: pngacn sre ecentes feted ely dau oution tax += sep feces control ens, althoeeh te ftal acer = bee tected ealtures, âthe activity semedauta saved simaiy atpase ate esee tofagâ \"fi ecto tdlas, phorbenensinincr 2 panna gabe ane led ant > ins ai? sepa. vg. daragar, u. rs poo. Â© : febispceas sea u's, âbaroni. cberansk, gor, seein). kline, med tmescow) asg), 76 : habe mmeae activites aldeate, phoxphollensane : ie\" shootase ere tds 20 contrat aod pate aeration alone eves shane # see ret kaa aidtase nthe saliva, reaâ * > fuente qa controle es ynis)._ kethetbode r=â pasate ta-tb unity comtgls 210 units. tae ares ehsl iene earn ne lod tem these: teding test a8 indicetor sbeumitereâ¢ eg unnn 2 anisina (cor ine smee dry baopeopstcenstl. zeb. delo werd, bturuia) teterâ finspece ith coned. luge som drop physi. -# > sade reults ext, baas 258 52 bees cad tine ite formation, 69 samples ol tren ters sh gave pon rents ita teste het ae âshould ised aÂ¢ 2 sunementary test z: ue âaide acuity dayne kinase [9 moube ected vith polyoma sivas. -g, fecerl g, cour sar aew) nature 2te(g0ed),. 181-2096\" âembry cel polyoma vas teoethne linnse ce) evi wi tax. 72 8 sahymibinest ioeabed ext eam 0 fested eels noe produce radioactive tdp 77 ected seti endl actety uninfected cel bf kettoal activ cy wonpyelaeaated exte sei fas stiin iirtes eels, evidently tetasecn'afecrot oan wnnfected cals. fection tou dae, yeaa rss et ins sal pas theca deen ee âselved yal bna synthesis tera edecte coritione ex.oo cequriane aboratory mice jackrabbits, giate forest gully winstonsalem, car), 7% ghee gtduor| ag). bpesntected female ee âip infected feat uctrabits none suse = cetafection farman malteps. combone ges sosceptiblty males wot females (14 4056 âlouse) mreased no. larvae 8.1508\" ped bere 1e7se_ tena ere reduction wr tot 8 opr git ge aes gea shed weencrnes shon), ron sf ee od\n",
      "Number of words in the sentence: 1129\n"
     ]
    }
   ],
   "source": [
    "# Find the sentence with the maximum number of words\n",
    "max_words_sentence = max(df.text, key=lambda x: len(x.split()))\n",
    "max_words_count = len(max_words_sentence.split())\n",
    "\n",
    "print(\"Sentence with the maximum words:\", max_words_sentence)\n",
    "print(\"Number of words in the sentence:\", max_words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=1000)\n",
    "X_train_bow = cv.fit_transform(X_train['text']).toarray()\n",
    "X_test_bow = cv.transform(X_test['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GaussianNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train_bow,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7198364008179959"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "y_pred = gnb.predict(X_test_bow)\n",
    "\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8425357873210634"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_bow,y_train)\n",
    "y_pred = rf.predict(X_test_bow)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8548057259713702"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(max_features=3000)\n",
    "\n",
    "X_train_bow = cv.fit_transform(X_train['text']).toarray()\n",
    "X_test_bow = cv.transform(X_test['text']).toarray()\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_bow,y_train)\n",
    "y_pred = rf.predict(X_test_bow)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8588957055214724"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=3000)\n",
    "X_train_bow = cv.fit_transform(X_train['text']).toarray()\n",
    "X_test_bow = cv.transform(X_test['text']).toarray()\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_bow,y_train)\n",
    "y_pred = rf.predict(X_test_bow)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2445, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hyperparatmeter using rid and randome search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Randomized Search for Logistic Regression\n",
      "Best parameters for Logistic Regression: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.01}\n",
      "Best score for Logistic Regression: 0.8072733441202569\n",
      "Performing Randomized Search for KNN\n",
      "Best parameters for KNN: {'weights': 'distance', 'n_neighbors': 3}\n",
      "Best score for KNN: 0.4023670337700297\n",
      "Performing Randomized Search for Naive Bayes\n",
      "Best parameters for Naive Bayes: {}\n",
      "Best score for Naive Bayes: 0.6692194269011953\n",
      "Performing Randomized Search for Decision Tree\n",
      "Best parameters for Decision Tree: {'max_depth': None, 'criterion': 'entropy'}\n",
      "Best score for Decision Tree: 0.6912051777232632\n",
      "Performing Randomized Search for Random Forest\n",
      "Best parameters for Random Forest: {'n_estimators': 100, 'max_depth': None}\n",
      "Best score for Random Forest: 0.8093037214885953\n",
      "Performing Randomized Search for AdaBoost\n",
      "Best parameters for AdaBoost: {'n_estimators': 200, 'learning_rate': 1}\n",
      "Best score for AdaBoost: 0.7581710945247664\n",
      "Performing Randomized Search for Gradient Boosting\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPerforming Randomized Search for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m random_search = RandomizedSearchCV(model, param_distributions=params, n_iter=\u001b[32m5\u001b[39m, cv=\u001b[32m5\u001b[39m, scoring=\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m, random_state=\u001b[32m42\u001b[39m)  \u001b[38;5;66;03m# Use 'accuracy' for classification\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mrandom_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_bow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest parameters for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrandom_search.best_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest score for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrandom_search.best_score_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AMBARKUMAR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AMBARKUMAR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AMBARKUMAR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AMBARKUMAR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AMBARKUMAR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AMBARKUMAR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AMBARKUMAR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AMBARKUMAR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AMBARKUMAR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:866\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    864\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    865\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m866\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    870\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AMBARKUMAR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AMBARKUMAR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:787\u001b[39m, in \u001b[36mBaseGradientBoosting.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, monitor)\u001b[39m\n\u001b[32m    784\u001b[39m     \u001b[38;5;28mself\u001b[39m._resize_state()\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m n_stages = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_stages != \u001b[38;5;28mself\u001b[39m.estimators_.shape[\u001b[32m0\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AMBARKUMAR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:883\u001b[39m, in \u001b[36mBaseGradientBoosting._fit_stages\u001b[39m\u001b[34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[39m\n\u001b[32m    876\u001b[39m         initial_loss = factor * \u001b[38;5;28mself\u001b[39m._loss(\n\u001b[32m    877\u001b[39m             y_true=y_oob_masked,\n\u001b[32m    878\u001b[39m             raw_prediction=raw_predictions[~sample_mask],\n\u001b[32m    879\u001b[39m             sample_weight=sample_weight_oob_masked,\n\u001b[32m    880\u001b[39m         )\n\u001b[32m    882\u001b[39m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m883\u001b[39m raw_predictions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AMBARKUMAR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:489\u001b[39m, in \u001b[36mBaseGradientBoosting._fit_stage\u001b[39m\u001b[34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[39m\n\u001b[32m    486\u001b[39m     sample_weight = sample_weight * sample_mask.astype(np.float64)\n\u001b[32m    488\u001b[39m X = X_csc \u001b[38;5;28;01mif\u001b[39;00m X_csc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_g_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[32m    494\u001b[39m X_for_tree_update = X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AMBARKUMAR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AMBARKUMAR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1404\u001b[39m, in \u001b[36mDecisionTreeRegressor.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input)\u001b[39m\n\u001b[32m   1374\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1375\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, check_input=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1376\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[32m   1377\u001b[39m \n\u001b[32m   1378\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1401\u001b[39m \u001b[33;03m        Fitted estimator.\u001b[39;00m\n\u001b[32m   1402\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1404\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1410\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AMBARKUMAR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    462\u001b[39m     builder = BestFirstTreeBuilder(\n\u001b[32m    463\u001b[39m         splitter,\n\u001b[32m    464\u001b[39m         min_samples_split,\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m         \u001b[38;5;28mself\u001b[39m.min_impurity_decrease,\n\u001b[32m    470\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_classes_ = \u001b[38;5;28mself\u001b[39m.n_classes_[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "classification_models = {\n",
    "    \"Logistic Regression\": (LogisticRegression(), {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}),\n",
    "    \"KNN\": (KNeighborsClassifier(), {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance']}),\n",
    "    \"Naive Bayes\": (GaussianNB(), {}),  # No hyperparameters to tune\n",
    "    #\"SVM\": (SVC(), {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly'], 'gamma': ['scale', 'auto']}),\n",
    "    #\"SVM\": (SVC(), {'C': [0.1, 1, 10], 'kernel': ['linear']}),\n",
    "    \"Decision Tree\": (DecisionTreeClassifier(), {'criterion': ['gini', 'entropy'], 'max_depth': [3, 5, 10, None]}),\n",
    "    \"Random Forest\": (RandomForestClassifier(), {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 10, None]}),\n",
    "    \"AdaBoost\": (AdaBoostClassifier(), {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1]}),\n",
    "    \"Gradient Boosting\": (GradientBoostingClassifier(), {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1], 'max_depth': [3, 5, 10]}),\n",
    "    \"XGBoost\": (XGBClassifier(), {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1], 'max_depth': [3, 5, 10]})\n",
    "}\n",
    "\n",
    "\n",
    "#random search\n",
    "for model_name, (model, params) in classification_models.items():\n",
    "    print(f\"Performing Randomized Search for {model_name}\")\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=params, n_iter=5, cv=5, scoring='accuracy', random_state=42)  # Use 'accuracy' for classification\n",
    "    random_search.fit(X_train_bow, y_train)\n",
    "    print(f\"Best parameters for {model_name}: {random_search.best_params_}\")\n",
    "    print(f\"Best score for {model_name}: {random_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2'])\n",
    "    }\n",
    "    \n",
    "    model = RandomForestClassifier(random_state=42, **params)\n",
    "    model.fit(X_train_bow, y_train)\n",
    "    val_preds = model.predict(X_test_bow)\n",
    "    accuracy = accuracy_score(y_test, val_preds)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-05 11:50:05,757] A new study created in memory with name: no-name-1872e9f2-359c-448b-b50a-643c0723aaeb\n",
      "[I 2025-04-05 11:50:07,942] Trial 0 finished with value: 0.7975460122699386 and parameters: {'n_estimators': 300, 'max_depth': 14, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 0 with value: 0.7975460122699386.\n",
      "[I 2025-04-05 11:50:12,205] Trial 1 finished with value: 0.7893660531697342 and parameters: {'n_estimators': 600, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 0 with value: 0.7975460122699386.\n",
      "[I 2025-04-05 11:50:18,440] Trial 2 finished with value: 0.7995910020449898 and parameters: {'n_estimators': 700, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.7995910020449898.\n",
      "[I 2025-04-05 11:50:24,331] Trial 3 finished with value: 0.7914110429447853 and parameters: {'n_estimators': 900, 'max_depth': 9, 'min_samples_split': 16, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 2 with value: 0.7995910020449898.\n",
      "[I 2025-04-05 11:50:27,168] Trial 4 finished with value: 0.7811860940695297 and parameters: {'n_estimators': 500, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 2 with value: 0.7995910020449898.\n",
      "[I 2025-04-05 11:50:29,193] Trial 5 finished with value: 0.7934560327198364 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.7995910020449898.\n",
      "[I 2025-04-05 11:50:40,553] Trial 6 finished with value: 0.8057259713701431 and parameters: {'n_estimators': 200, 'max_depth': 14, 'min_samples_split': 17, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 6 with value: 0.8057259713701431.\n",
      "[I 2025-04-05 11:50:43,572] Trial 7 finished with value: 0.7709611451942741 and parameters: {'n_estimators': 300, 'max_depth': 4, 'min_samples_split': 17, 'min_samples_leaf': 9, 'max_features': 'sqrt'}. Best is trial 6 with value: 0.8057259713701431.\n",
      "[I 2025-04-05 11:50:45,744] Trial 8 finished with value: 0.7914110429447853 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 6 with value: 0.8057259713701431.\n",
      "[I 2025-04-05 11:51:18,889] Trial 9 finished with value: 0.8016359918200409 and parameters: {'n_estimators': 800, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 6 with value: 0.8057259713701431.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 10\n",
      "Best trial: {'n_estimators': 200, 'max_depth': 14, 'min_samples_split': 17, 'min_samples_leaf': 6, 'max_features': 'sqrt'}\n",
      "Best accuracy: 0.8057259713701431\n"
     ]
    }
   ],
   "source": [
    "## Run Optuna Bayesian Optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Number of finished trials:\", len(study.trials))\n",
    "print(\"Best trial:\", study.best_trial.params)\n",
    "print(\"Best accuracy:\", study.best_trial.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with best hyperparameters: 0.8057259713701431\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "best_params = study.best_trial.params\n",
    "final_model = RandomForestClassifier(random_state=42, **best_params)\n",
    "final_model.fit(X_train_bow, y_train)\n",
    "test_preds = final_model.predict(X_test_bow)\n",
    "test_accuracy = accuracy_score(y_test, test_preds)\n",
    "\n",
    "print(\"Test Accuracy with best hyperparameters:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualizations\n",
    "from optuna.visualization import plot_optimization_history, plot_parallel_coordinate, plot_slice, plot_contour, plot_param_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated labels: [0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)  # Converts labels to sequential values\n",
    "print(\"Updated labels:\", np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna for multiple models\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier  # Import XGBoost\n",
    "\n",
    "def objective(trial):\n",
    "    # Choose the algorithm to tune\n",
    "    #classifier_name = trial.suggest_categorical('classifier', ['SVM', 'RandomForest', 'GradientBoosting', 'XGBoost'])\n",
    "    classifier_name = trial.suggest_categorical('classifier', ['SVM', 'RandomForest', 'XGBoost'])\n",
    "\n",
    "    \n",
    "    if classifier_name == 'SVM':\n",
    "        # SVM hyperparameters\n",
    "        c = trial.suggest_float('C', 0.1, 100, log=True)\n",
    "        kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly', 'sigmoid'])\n",
    "        gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "\n",
    "        model = SVC(C=c, kernel=kernel, gamma=gamma, random_state=42)\n",
    "\n",
    "    elif classifier_name == 'RandomForest':\n",
    "        # Random Forest hyperparameters\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "        min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "        bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
    "\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            bootstrap=bootstrap,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    elif classifier_name == 'GradientBoosting':\n",
    "        # Gradient Boosting hyperparameters\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "        learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "        min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "\n",
    "        model = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    elif classifier_name == 'XGBoost':\n",
    "        # XGBoost hyperparameters\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 100,200)\n",
    "        learning_rate = trial.suggest_float('learning_rate', 0.01, 0.1, log=True)\n",
    "        max_depth = trial.suggest_int('max_depth', 5,10)\n",
    "        colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "        subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "\n",
    "        #\"XGBoost\": (XGBClassifier(), {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1], 'max_depth': [3, 5, 10]})\n",
    "        model = XGBClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            max_depth=max_depth,\n",
    "            colsample_bytree=colsample_bytree,\n",
    "            subsample=subsample,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    # Perform cross-validation and return the mean accuracy\n",
    "    score = cross_val_score(model, X_train_bow, y_train, cv=3, scoring='accuracy').mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-05 17:31:01,100] A new study created in memory with name: no-name-a113efbf-4c05-4591-a5fa-189aeeb072cb\n",
      "[I 2025-04-05 17:31:10,036] Trial 0 finished with value: 0.7576687116564417 and parameters: {'classifier': 'RandomForest', 'n_estimators': 58, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 10, 'bootstrap': False}. Best is trial 0 with value: 0.7576687116564417.\n",
      "[I 2025-04-05 17:31:40,944] Trial 1 finished with value: 0.6952965235173824 and parameters: {'classifier': 'SVM', 'C': 3.3359508076234685, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.7576687116564417.\n",
      "[I 2025-04-05 17:31:46,998] Trial 2 finished with value: 0.7571574642126789 and parameters: {'classifier': 'RandomForest', 'n_estimators': 244, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 6, 'bootstrap': False}. Best is trial 0 with value: 0.7576687116564417.\n",
      "[I 2025-04-05 17:32:07,292] Trial 3 finished with value: 0.7765848670756647 and parameters: {'classifier': 'XGBoost', 'n_estimators': 50, 'learning_rate': 0.013377364574305262, 'max_depth': 6, 'colsample_bytree': 0.6980561726730234, 'subsample': 0.7093072635697746}. Best is trial 3 with value: 0.7765848670756647.\n",
      "[I 2025-04-05 17:32:28,571] Trial 4 finished with value: 0.7908997955010225 and parameters: {'classifier': 'XGBoost', 'n_estimators': 50, 'learning_rate': 0.03693467470072843, 'max_depth': 7, 'colsample_bytree': 0.5499242688358543, 'subsample': 0.7988534436685238}. Best is trial 4 with value: 0.7908997955010225.\n",
      "[I 2025-04-05 17:32:43,128] Trial 5 finished with value: 0.778118609406953 and parameters: {'classifier': 'RandomForest', 'n_estimators': 275, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 4 with value: 0.7908997955010225.\n",
      "[I 2025-04-05 17:32:52,504] Trial 6 finished with value: 0.7668711656441718 and parameters: {'classifier': 'RandomForest', 'n_estimators': 249, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 7, 'bootstrap': True}. Best is trial 4 with value: 0.7908997955010225.\n",
      "[I 2025-04-05 17:33:13,720] Trial 7 finished with value: 0.7791411042944786 and parameters: {'classifier': 'XGBoost', 'n_estimators': 50, 'learning_rate': 0.05591070941711984, 'max_depth': 6, 'colsample_bytree': 0.9182573554547129, 'subsample': 0.718389857235074}. Best is trial 4 with value: 0.7908997955010225.\n",
      "[I 2025-04-05 17:33:24,711] Trial 8 finished with value: 0.7740286298568507 and parameters: {'classifier': 'RandomForest', 'n_estimators': 240, 'max_depth': 13, 'min_samples_split': 9, 'min_samples_leaf': 6, 'bootstrap': True}. Best is trial 4 with value: 0.7908997955010225.\n",
      "[I 2025-04-05 17:33:29,226] Trial 9 finished with value: 0.7699386503067484 and parameters: {'classifier': 'RandomForest', 'n_estimators': 98, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 4 with value: 0.7908997955010225.\n"
     ]
    }
   ],
   "source": [
    "# Create a study and optimize it using CmaEsSampler\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial parameters: {'classifier': 'XGBoost', 'n_estimators': 50, 'learning_rate': 0.03693467470072843, 'max_depth': 7, 'colsample_bytree': 0.5499242688358543, 'subsample': 0.7988534436685238}\n",
      "Best trial accuracy: 0.7908997955010225\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best trial\n",
    "best_trial = study.best_trial\n",
    "print(\"Best trial parameters:\", best_trial.params)\n",
    "print(\"Best trial accuracy:\", best_trial.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_C</th>\n",
       "      <th>params_bootstrap</th>\n",
       "      <th>params_classifier</th>\n",
       "      <th>params_colsample_bytree</th>\n",
       "      <th>params_gamma</th>\n",
       "      <th>params_kernel</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_min_samples_leaf</th>\n",
       "      <th>params_min_samples_split</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>params_subsample</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.757669</td>\n",
       "      <td>2025-04-05 17:31:01.104425</td>\n",
       "      <td>2025-04-05 17:31:10.036026</td>\n",
       "      <td>0 days 00:00:08.931601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.695297</td>\n",
       "      <td>2025-04-05 17:31:10.044595</td>\n",
       "      <td>2025-04-05 17:31:40.943595</td>\n",
       "      <td>0 days 00:00:30.899000</td>\n",
       "      <td>3.335951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SVM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.757157</td>\n",
       "      <td>2025-04-05 17:31:40.946415</td>\n",
       "      <td>2025-04-05 17:31:46.997862</td>\n",
       "      <td>0 days 00:00:06.051447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.776585</td>\n",
       "      <td>2025-04-05 17:31:47.000860</td>\n",
       "      <td>2025-04-05 17:32:07.291984</td>\n",
       "      <td>0 days 00:00:20.291124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.698056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.709307</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.790900</td>\n",
       "      <td>2025-04-05 17:32:07.295156</td>\n",
       "      <td>2025-04-05 17:32:28.570837</td>\n",
       "      <td>0 days 00:00:21.275681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.549924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036935</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.798853</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.778119</td>\n",
       "      <td>2025-04-05 17:32:28.577149</td>\n",
       "      <td>2025-04-05 17:32:43.127588</td>\n",
       "      <td>0 days 00:00:14.550439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.766871</td>\n",
       "      <td>2025-04-05 17:32:43.132231</td>\n",
       "      <td>2025-04-05 17:32:52.503753</td>\n",
       "      <td>0 days 00:00:09.371522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.779141</td>\n",
       "      <td>2025-04-05 17:32:52.507512</td>\n",
       "      <td>2025-04-05 17:33:13.719713</td>\n",
       "      <td>0 days 00:00:21.212201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.918257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.055911</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.718390</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.774029</td>\n",
       "      <td>2025-04-05 17:33:13.722912</td>\n",
       "      <td>2025-04-05 17:33:24.711084</td>\n",
       "      <td>0 days 00:00:10.988172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.769939</td>\n",
       "      <td>2025-04-05 17:33:24.712571</td>\n",
       "      <td>2025-04-05 17:33:29.225949</td>\n",
       "      <td>0 days 00:00:04.513378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number     value             datetime_start          datetime_complete  \\\n",
       "0       0  0.757669 2025-04-05 17:31:01.104425 2025-04-05 17:31:10.036026   \n",
       "1       1  0.695297 2025-04-05 17:31:10.044595 2025-04-05 17:31:40.943595   \n",
       "2       2  0.757157 2025-04-05 17:31:40.946415 2025-04-05 17:31:46.997862   \n",
       "3       3  0.776585 2025-04-05 17:31:47.000860 2025-04-05 17:32:07.291984   \n",
       "4       4  0.790900 2025-04-05 17:32:07.295156 2025-04-05 17:32:28.570837   \n",
       "5       5  0.778119 2025-04-05 17:32:28.577149 2025-04-05 17:32:43.127588   \n",
       "6       6  0.766871 2025-04-05 17:32:43.132231 2025-04-05 17:32:52.503753   \n",
       "7       7  0.779141 2025-04-05 17:32:52.507512 2025-04-05 17:33:13.719713   \n",
       "8       8  0.774029 2025-04-05 17:33:13.722912 2025-04-05 17:33:24.711084   \n",
       "9       9  0.769939 2025-04-05 17:33:24.712571 2025-04-05 17:33:29.225949   \n",
       "\n",
       "                duration  params_C params_bootstrap params_classifier  \\\n",
       "0 0 days 00:00:08.931601       NaN            False      RandomForest   \n",
       "1 0 days 00:00:30.899000  3.335951              NaN               SVM   \n",
       "2 0 days 00:00:06.051447       NaN            False      RandomForest   \n",
       "3 0 days 00:00:20.291124       NaN              NaN           XGBoost   \n",
       "4 0 days 00:00:21.275681       NaN              NaN           XGBoost   \n",
       "5 0 days 00:00:14.550439       NaN             True      RandomForest   \n",
       "6 0 days 00:00:09.371522       NaN             True      RandomForest   \n",
       "7 0 days 00:00:21.212201       NaN              NaN           XGBoost   \n",
       "8 0 days 00:00:10.988172       NaN             True      RandomForest   \n",
       "9 0 days 00:00:04.513378       NaN             True      RandomForest   \n",
       "\n",
       "   params_colsample_bytree params_gamma params_kernel  params_learning_rate  \\\n",
       "0                      NaN          NaN           NaN                   NaN   \n",
       "1                      NaN         auto           rbf                   NaN   \n",
       "2                      NaN          NaN           NaN                   NaN   \n",
       "3                 0.698056          NaN           NaN              0.013377   \n",
       "4                 0.549924          NaN           NaN              0.036935   \n",
       "5                      NaN          NaN           NaN                   NaN   \n",
       "6                      NaN          NaN           NaN                   NaN   \n",
       "7                 0.918257          NaN           NaN              0.055911   \n",
       "8                      NaN          NaN           NaN                   NaN   \n",
       "9                      NaN          NaN           NaN                   NaN   \n",
       "\n",
       "   params_max_depth  params_min_samples_leaf  params_min_samples_split  \\\n",
       "0               8.0                     10.0                       5.0   \n",
       "1               NaN                      NaN                       NaN   \n",
       "2               3.0                      6.0                       5.0   \n",
       "3               6.0                      NaN                       NaN   \n",
       "4               7.0                      NaN                       NaN   \n",
       "5              14.0                      4.0                       6.0   \n",
       "6               9.0                      7.0                      10.0   \n",
       "7               6.0                      NaN                       NaN   \n",
       "8              13.0                      6.0                       9.0   \n",
       "9              12.0                      4.0                       4.0   \n",
       "\n",
       "   params_n_estimators  params_subsample     state  \n",
       "0                 58.0               NaN  COMPLETE  \n",
       "1                  NaN               NaN  COMPLETE  \n",
       "2                244.0               NaN  COMPLETE  \n",
       "3                 50.0          0.709307  COMPLETE  \n",
       "4                 50.0          0.798853  COMPLETE  \n",
       "5                275.0               NaN  COMPLETE  \n",
       "6                249.0               NaN  COMPLETE  \n",
       "7                 50.0          0.718390  COMPLETE  \n",
       "8                240.0               NaN  COMPLETE  \n",
       "9                 98.0               NaN  COMPLETE  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "params_classifier\n",
       "RandomForest    6\n",
       "XGBoost         3\n",
       "SVM             1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe()['params_classifier'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "params_classifier\n",
       "RandomForest    0.767297\n",
       "SVM             0.695297\n",
       "XGBoost         0.782209\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe().groupby('params_classifier')['value'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated labels: [0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)  # Converts labels to sequential values\n",
    "print(\"Updated labels:\", np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with best hyperparameters: 0.8343558282208589\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "best_params = study.best_trial.params\n",
    "final_model = XGBClassifier(random_state=42, **best_params)\n",
    "final_model.fit(X_train_bow, y_train)\n",
    "test_preds = final_model.predict(X_test_bow)\n",
    "test_accuracy = accuracy_score(y_test, test_preds)\n",
    "\n",
    "print(\"Test Accuracy with best hyperparameters:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
