{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpeGnSdQihbM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4xtLLvVSF6MO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "data=pd.read_csv('hindi_english_parallel2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KtMgl7xhnajs",
        "outputId": "1f17ddb8-9746-41f3-d763-2c1587ae9a0f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Help!</td>\n",
              "      <td>बचाओ!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jump.</td>\n",
              "      <td>उछलो.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Jump.</td>\n",
              "      <td>कूदो.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jump.</td>\n",
              "      <td>छलांग.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>नमस्ते।</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  English    Hindi\n",
              "0   Help!    बचाओ!\n",
              "1   Jump.    उछलो.\n",
              "2   Jump.    कूदो.\n",
              "3   Jump.   छलांग.\n",
              "4  Hello!  नमस्ते।"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FrsGifo9k5a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKYPNo5Unb_Y",
        "outputId": "32c9b589-047c-4818-ebba-ad5e44b4485f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(130476, 2)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1CT6C6UGp2nM"
      },
      "outputs": [],
      "source": [
        "\n",
        "START_TOKEN = '<start>'\n",
        "PADDING_TOKEN = '<padding>'\n",
        "END_TOKEN = '<end>'\n",
        "\n",
        "english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "                      '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', '@',\n",
        "                      'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "                      'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
        "                      'Y', 'Z', '[', '\\\\', ']', '^', '_', '`',\n",
        "                      'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "                      'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
        "                      'y', 'z', '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]\n",
        "\n",
        "\n",
        "\n",
        "hindi_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "                    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', 'ँ', 'ं', 'ः',\n",
        "                    'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऌ', 'ए', 'ऐ', 'ओ', 'औ',\n",
        "                    'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण',\n",
        "                    'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श', 'ष', 'स', 'ह',\n",
        "                    '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्', 'ॐ',\n",
        "                    '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', PADDING_TOKEN, END_TOKEN]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxpfaRZ6rA4Y",
        "outputId": "f370ff67-74b1-4568-9911-74cd74e31a47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "97"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(english_vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt4y6thorPl7",
        "outputId": "fb219ac5-b493-462a-e555-b22be745ff94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "109"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(hindi_vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Nv_uzCz4rStL",
        "outputId": "7039cb1f-7f3b-4465-b5e8-f5013dbf4134"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ईउ'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'ई'+ 'उ'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "I3hFwHuFraFl"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "index_to_hindi = {k:v for k,v in enumerate(hindi_vocabulary)}\n",
        "hindi_to_index = {v:k for k,v in enumerate(hindi_vocabulary)}\n",
        "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
        "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUndJJmbrjKS",
        "outputId": "b81ee021-da38-44fa-bf98-35a21ea28566"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: '<start>',\n",
              " 1: ' ',\n",
              " 2: '!',\n",
              " 3: '\"',\n",
              " 4: '#',\n",
              " 5: '$',\n",
              " 6: '%',\n",
              " 7: '&',\n",
              " 8: \"'\",\n",
              " 9: '(',\n",
              " 10: ')',\n",
              " 11: '*',\n",
              " 12: '+',\n",
              " 13: ',',\n",
              " 14: '-',\n",
              " 15: '.',\n",
              " 16: '/',\n",
              " 17: '0',\n",
              " 18: '1',\n",
              " 19: '2',\n",
              " 20: '3',\n",
              " 21: '4',\n",
              " 22: '5',\n",
              " 23: '6',\n",
              " 24: '7',\n",
              " 25: '8',\n",
              " 26: '9',\n",
              " 27: ':',\n",
              " 28: '<',\n",
              " 29: '=',\n",
              " 30: '>',\n",
              " 31: '?',\n",
              " 32: 'ँ',\n",
              " 33: 'ं',\n",
              " 34: 'ः',\n",
              " 35: 'अ',\n",
              " 36: 'आ',\n",
              " 37: 'इ',\n",
              " 38: 'ई',\n",
              " 39: 'उ',\n",
              " 40: 'ऊ',\n",
              " 41: 'ऋ',\n",
              " 42: 'ऌ',\n",
              " 43: 'ए',\n",
              " 44: 'ऐ',\n",
              " 45: 'ओ',\n",
              " 46: 'औ',\n",
              " 47: 'क',\n",
              " 48: 'ख',\n",
              " 49: 'ग',\n",
              " 50: 'घ',\n",
              " 51: 'ङ',\n",
              " 52: 'च',\n",
              " 53: 'छ',\n",
              " 54: 'ज',\n",
              " 55: 'झ',\n",
              " 56: 'ञ',\n",
              " 57: 'ट',\n",
              " 58: 'ठ',\n",
              " 59: 'ड',\n",
              " 60: 'ढ',\n",
              " 61: 'ण',\n",
              " 62: 'त',\n",
              " 63: 'थ',\n",
              " 64: 'द',\n",
              " 65: 'ध',\n",
              " 66: 'न',\n",
              " 67: 'प',\n",
              " 68: 'फ',\n",
              " 69: 'ब',\n",
              " 70: 'भ',\n",
              " 71: 'म',\n",
              " 72: 'य',\n",
              " 73: 'र',\n",
              " 74: 'ल',\n",
              " 75: 'व',\n",
              " 76: 'श',\n",
              " 77: 'ष',\n",
              " 78: 'स',\n",
              " 79: 'ह',\n",
              " 80: '़',\n",
              " 81: 'ऽ',\n",
              " 82: 'ा',\n",
              " 83: 'ि',\n",
              " 84: 'ी',\n",
              " 85: 'ु',\n",
              " 86: 'ू',\n",
              " 87: 'ृ',\n",
              " 88: 'ॄ',\n",
              " 89: 'ॅ',\n",
              " 90: 'े',\n",
              " 91: 'ै',\n",
              " 92: 'ॉ',\n",
              " 93: 'ो',\n",
              " 94: 'ौ',\n",
              " 95: '्',\n",
              " 96: 'ॐ',\n",
              " 97: '०',\n",
              " 98: '१',\n",
              " 99: '२',\n",
              " 100: '३',\n",
              " 101: '४',\n",
              " 102: '५',\n",
              " 103: '६',\n",
              " 104: '७',\n",
              " 105: '८',\n",
              " 106: '९',\n",
              " 107: '<padding>',\n",
              " 108: '<end>'}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index_to_hindi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7t92ynGsRn3B",
        "outputId": "f00ab019-82d9-42a2-d156-37d8382cceac"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ac505861-a8e6-4c68-8657-8fadd08677de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Help!</td>\n",
              "      <td>बचाओ!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jump.</td>\n",
              "      <td>उछलो.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Jump.</td>\n",
              "      <td>कूदो.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jump.</td>\n",
              "      <td>छलांग.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>नमस्ते।</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac505861-a8e6-4c68-8657-8fadd08677de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac505861-a8e6-4c68-8657-8fadd08677de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac505861-a8e6-4c68-8657-8fadd08677de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0fb317ed-5ee4-47e2-8354-708761492a6a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0fb317ed-5ee4-47e2-8354-708761492a6a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0fb317ed-5ee4-47e2-8354-708761492a6a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  English    Hindi\n",
              "0   Help!    बचाओ!\n",
              "1   Jump.    उछलो.\n",
              "2   Jump.    कूदो.\n",
              "3   Jump.   छलांग.\n",
              "4  Hello!  नमस्ते।"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMuRglwTR3aI",
        "outputId": "a74300fe-7aff-47f7-887e-96b57f56961a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(130476, 2)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pludaSe-R4iI",
        "outputId": "3a304c69-83c3-495b-8910-acda6303179c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"sample\",\n  \"rows\": 100000,\n  \"fields\": [\n    {\n      \"column\": \"english\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 19250,\n        \"samples\": [\n          \"Whether the actor is shown when parented\",\n          \"Moving an event into the calendar '{0}'\",\n          \"Minification Filter\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hindi\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18189,\n        \"samples\": [\n          \"SSLLink\\u2026 \\\").\\\" Link\",\n          \"'% s' \\u092a\\u0902\\u091a\\u093e\\u0902\\u0917 \\u0915\\u094b \\u092a\\u094d\\u0930\\u0947\\u0937\\u093f\\u0924 \\u0938\\u094d\\u0935\\u0940\\u0915\\u0943\\u0924 \\u0939\\u0941\\u0906\",\n          \"\\u0916\\u094b\\u091c \\u092b\\u093c\\u094b\\u0932\\u094d\\u0921\\u0930 \\u0938\\u094d\\u0935\\u0924\\u0903 \\u0905\\u0926\\u094d\\u092f\\u0924\\u0928\\u0940\\u0915\\u0943\\u0924 \\u0939\\u094b \\u0917\\u092f\\u093e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "sample"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-5a550e64-26c2-44b3-afdf-060e87b2c567\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Give your application an accessibility workout</td>\n",
              "      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Accerciser Accessibility Explorer</td>\n",
              "      <td>एक्सेर्साइसर पहुंचनीयता अन्वेषक</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The default plugin layout for the bottom panel</td>\n",
              "      <td>निचले पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The default plugin layout for the top panel</td>\n",
              "      <td>ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A list of plugins that are disabled by default</td>\n",
              "      <td>उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a550e64-26c2-44b3-afdf-060e87b2c567')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5a550e64-26c2-44b3-afdf-060e87b2c567 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5a550e64-26c2-44b3-afdf-060e87b2c567');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e3bd1c73-4607-4619-a203-4e1653e787df\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e3bd1c73-4607-4619-a203-4e1653e787df')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e3bd1c73-4607-4619-a203-4e1653e787df button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                          english  \\\n",
              "0  Give your application an accessibility workout   \n",
              "1               Accerciser Accessibility Explorer   \n",
              "2  The default plugin layout for the bottom panel   \n",
              "3     The default plugin layout for the top panel   \n",
              "4  A list of plugins that are disabled by default   \n",
              "\n",
              "                                               hindi  \n",
              "0    अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें  \n",
              "1                    एक्सेर्साइसर पहुंचनीयता अन्वेषक  \n",
              "2              निचले पटल के लिए डिफोल्ट प्लग-इन खाका  \n",
              "3               ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका  \n",
              "4  उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample=df[:100000]\n",
        "sample.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "iT1-YvYNR8lC",
        "outputId": "c7221d50-b9de-4d2c-ce93-bcc712fd3e98"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>एक्सेर्साइसर पहुंचनीयता अन्वेषक</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>निचले पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0    अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें\n",
              "1                    एक्सेर्साइसर पहुंचनीयता अन्वेषक\n",
              "2              निचले पटल के लिए डिफोल्ट प्लग-इन खाका\n",
              "3               ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका\n",
              "Name: hindi, dtype: object"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "sample['hindi'][:4].apply(lambda x: re.sub(\"'\", '', x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kQBIbx0THQD",
        "outputId": "3a85678e-81c5-4e31-f636-e2582859ecee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें',\n",
              " 'एक्सेर्साइसर पहुंचनीयता अन्वेषक',\n",
              " 'निचले पटल के लिए डिफोल्ट प्लग-इन खाका',\n",
              " 'ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका',\n",
              " 'उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है',\n",
              " 'अवधि को हाइलाइट रकें',\n",
              " 'पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्से की अवधि',\n",
              " 'सीमांत (बोर्डर) के रंग को हाइलाइट करें',\n",
              " 'हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता। ',\n",
              " 'भराई के रंग को हाइलाइट करें']"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample['hindi'].to_list()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL-tEcr6HARh",
        "outputId": "a7877f6c-258c-47fd-d972-c97077bf71d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Give your application an accessibility workout',\n",
              " 'Accerciser Accessibility Explorer',\n",
              " 'The default plugin layout for the bottom panel',\n",
              " 'The default plugin layout for the top panel',\n",
              " 'A list of plugins that are disabled by default',\n",
              " 'Highlight duration',\n",
              " 'The duration of the highlight box when selecting accessible nodes',\n",
              " 'Highlight border color',\n",
              " 'The color and opacity of the highlight border.',\n",
              " 'Highlight fill color']"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "engsen=sample['english'].to_list()\n",
        "engsen[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "XMPi481bIr9D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB71mLv2IIfA",
        "outputId": "ac1e2a0c-9f79-4d6a-d6f8-0743866721cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें',\n",
              " 'एक्सेर्साइसर पहुंचनीयता अन्वेषक',\n",
              " 'निचले पटल के लिए डिफोल्ट प्लग-इन खाका',\n",
              " 'ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका',\n",
              " 'उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है',\n",
              " 'अवधि को हाइलाइट रकें',\n",
              " 'पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्से की अवधि',\n",
              " 'सीमांत (बोर्डर) के रंग को हाइलाइट करें',\n",
              " 'हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता। ',\n",
              " 'भराई के रंग को हाइलाइट करें']"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hindisen=sample['hindi'].to_list()\n",
        "hindisen[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeO9gaP5I-Bc",
        "outputId": "22f981d8-88e5-427f-b168-e2503751f498"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Give your application an accessibility workout\n",
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "for i in engsen:\n",
        "  print(i)\n",
        "  print(type(i))\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I56hOwHiI-6V",
        "outputId": "f4063ff4-26be-41e6-8f1d-c27f204ffbd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Give your application an accessibility workout',\n",
              " 'Accerciser Accessibility Explorer']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[sentence.rstrip('\\n') for sentence in engsen[:2]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "qVjjfE2-IYxn"
      },
      "outputs": [],
      "source": [
        "engsen = [str(sentence).rstrip('\\n') for sentence in engsen]\n",
        "hindisen = [str(sentence).rstrip('\\n') for sentence in hindisen]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYV-1853JWnE",
        "outputId": "1f464494-b0e6-470c-816f-77950cf6966e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['Give your application an accessibility workout',\n",
              "  'Accerciser Accessibility Explorer'],\n",
              " ['अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें',\n",
              "  'एक्सेर्साइसर पहुंचनीयता अन्वेषक'])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "engsen[:2],hindisen[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVv3ZTFhJYRT",
        "outputId": "97cefde6-e424-4ca2-ff1c-58f9a05c99d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1298, 1090)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(len(x) for x in engsen), max(len(x) for x in hindisen),\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiMUXrCoJy1j",
        "outputId": "88add21a-a948-43c7-9fcd-0de605a763be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97th percentile length Kannada: 91.0\n",
            "97th percentile length English: 88.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "PERCENTILE = 97\n",
        "print( f\"{PERCENTILE}th percentile length Kannada: {np.percentile([len(x) for x in hindisen], PERCENTILE)}\" )\n",
        "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in engsen], PERCENTILE)}\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XexCHrqFKf4n",
        "outputId": "65ddbc9d-6d84-45d7-a900-c429d5414c81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sentences: 100000\n",
            "Number of valid sentences: 64908\n"
          ]
        }
      ],
      "source": [
        "\n",
        "max_sequence_length = 200\n",
        "# to check if a token or character/alphabet ins engsen or hindi is present in about hindi/eng vocab pf charceter\n",
        "def is_valid_tokens(sentence, vocab):\n",
        "    for token in list(set(sentence)):\n",
        "        if token not in vocab:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "#to check if engsend or hindisen each sent has max 200 charcers\n",
        "def is_valid_length(sentence, max_sequence_length):\n",
        "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
        "\n",
        "valid_sentence_indicies = []\n",
        "for index in range(len(hindisen)):\n",
        "    hindi_sentence, english_sentence = hindisen[index], engsen[index]\n",
        "    if is_valid_length(hindi_sentence, max_sequence_length) \\\n",
        "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
        "      and is_valid_tokens(hindi_sentence, hindi_vocabulary):\n",
        "        valid_sentence_indicies.append(index)\n",
        "\n",
        "print(f\"Number of sentences: {len(hindisen)}\")\n",
        "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "7-I_719ELj_7"
      },
      "outputs": [],
      "source": [
        "#to craeted cuomt dataset pytorch inbuitl method used in our own csutom datas set class\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "\n",
        "    def __init__(self, english_sentences, kannada_sentences):\n",
        "        self.english_sentences = english_sentences\n",
        "        self.kannada_sentences = kannada_sentences\n",
        "    #rturn number of eng/hind or sentences in a list\n",
        "    def __len__(self):\n",
        "        return len(self.english_sentences)\n",
        "    #return 1:1 mapping of one lang to other\n",
        "    def __getitem__(self, idx):\n",
        "        return self.english_sentences[idx], self.kannada_sentences[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61fBkUM9Mmpe",
        "outputId": "cf252640-d044-4c96-8be4-ac7d798bf248"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "('How are you?', 'ನೀವು ಹೇಗಿದ್ದೀರಾ?')\n"
          ]
        }
      ],
      "source": [
        "#example\n",
        "# Sample data\n",
        "english_sentences = [\"Hello\", \"How are you?\", \"Good morning\"]\n",
        "kannada_sentences = [\"ಹಲೋ\", \"ನೀವು ಹೇಗಿದ್ದೀರಾ?\", \"ಶುಭೋದಯ\"]\n",
        "\n",
        "# Create dataset\n",
        "dataset = TextDataset(english_sentences, kannada_sentences)\n",
        "\n",
        "# Check dataset length\n",
        "print(len(dataset))  # Output: 3\n",
        "\n",
        "# Fetch a sample sentence pair\n",
        "print(dataset[1])  # Output: (\"How are you?\", \"ನೀವು ಹೇಗಿದ್ದೀರಾ?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDXpa1kTMrD_",
        "outputId": "12711b43-6e00-4490-80cc-397c7b91f668"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['Hello', 'How are you?', 'Good morning'],\n",
              " ['ಹಲೋ', 'ನೀವು ಹೇಗಿದ್ದೀರಾ?', 'ಶುಭೋದಯ'])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.english_sentences,dataset.kannada_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kAzZ8x7Mwfi",
        "outputId": "098ffdea-ad3d-4e35-ffe3-4114becf2257"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('How are you?', 'ನೀವು ಹೇಗಿದ್ದೀರಾ?')"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "gkRxbWNTN_JX"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset = TextDataset(engsen, hindisen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZyvNB7iOdIO",
        "outputId": "9755bd9e-9d11-4c0f-b349-8a27c34a9d8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('The color and opacity of the highlight fill.',\n",
              " 'हाइलाइट किया गया भराई का रंग और पारदर्शिता। ')"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc9Xgs0hOeeC",
        "outputId": "1115d52c-cb0e-4197-df4b-a432bc3b4e0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Give your application an accessibility workout', 'Accerciser Accessibility Explorer', 'The default plugin layout for the bottom panel'), ('अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें', 'एक्सेर्साइसर पहुंचनीयता अन्वेषक', 'निचले पटल के लिए डिफोल्ट प्लग-इन खाका')]\n",
            "[('The default plugin layout for the top panel', 'A list of plugins that are disabled by default', 'Highlight duration'), ('ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका', 'उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है', 'अवधि को हाइलाइट रकें')]\n",
            "[('The duration of the highlight box when selecting accessible nodes', 'Highlight border color', 'The color and opacity of the highlight border.'), ('पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्से की अवधि', 'सीमांत (बोर्डर) के रंग को हाइलाइट करें', 'हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता। ')]\n",
            "[('Highlight fill color', 'The color and opacity of the highlight fill.', 'API Browser'), ('भराई के रंग को हाइलाइट करें', 'हाइलाइट किया गया भराई का रंग और पारदर्शिता। ', 'एपीआई विचरक')]\n",
            "[('Browse the various methods of the current accessible', 'Hide private attributes', 'Method'), ('इस समय जिसे प्राप्त किया गया हो, उसकी विभिन्न विधियों (मेथड) में विचरण करें', 'निजी गुणों को छिपाएं', 'विधि')]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "batch_size = 3\n",
        "train_loader = DataLoader(dataset, batch_size)\n",
        "iterator = iter(train_loader)\n",
        "\n",
        "for batch_num, batch in enumerate(iterator):\n",
        "    print(batch)\n",
        "    if batch_num > 3:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "tMrtZTbBCbcR"
      },
      "outputs": [],
      "source": [
        "\n",
        "def tokenize(sentence, language_to_index, start_token=True, end_token=True):\n",
        "    sentence_word_indicies = [language_to_index[token] for token in list(sentence)]\n",
        "    if start_token:\n",
        "        sentence_word_indicies.insert(0, language_to_index[START_TOKEN])\n",
        "    if end_token:\n",
        "        sentence_word_indicies.append(language_to_index[END_TOKEN])\n",
        "    for _ in range(len(sentence_word_indicies), max_sequence_length):\n",
        "        sentence_word_indicies.append(language_to_index[PADDING_TOKEN])\n",
        "    return torch.tensor(sentence_word_indicies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCNC0_ezEGc3",
        "outputId": "cb88463d-5d21-4f4e-a951-b5f2e672926a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Browse the various methods of the current accessible',\n",
              "  'Hide private attributes',\n",
              "  'Method'),\n",
              " ('इस समय जिसे प्राप्त किया गया हो, उसकी विभिन्न विधियों (मेथड) में विचरण करें',\n",
              "  'निजी गुणों को छिपाएं',\n",
              "  'विधि')]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "pur8v61DEHUl"
      },
      "outputs": [],
      "source": [
        "eng_tokenized, hn_tokenized = [], []\n",
        "for sentence_num in range(batch_size):\n",
        "    eng_sentence, hn_sentence = batch[0][sentence_num], batch[1][sentence_num]\n",
        "    eng_tokenized.append( tokenize(eng_sentence, english_to_index, start_token=False, end_token=False) )\n",
        "    hn_tokenized.append( tokenize(hn_sentence, hindi_to_index, start_token=True, end_token=True) )\n",
        "eng_tokenized = torch.stack(eng_tokenized)\n",
        "hn_tokenized = torch.stack(hn_tokenized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yr7Hokn0GKE9",
        "outputId": "654ea7a5-4ac5-4087-cabb-0541e6412842"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[34, 82, 79, 87, 83, 69,  1, 84, 72, 69,  1, 86, 65, 82, 73, 79, 85, 83,\n",
              "          1, 77, 69, 84, 72, 79, 68, 83,  1, 79, 70,  1, 84, 72, 69,  1, 67, 85,\n",
              "         82, 82, 69, 78, 84,  1, 65, 67, 67, 69, 83, 83, 73, 66, 76, 69, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95],\n",
              "        [40, 73, 68, 69,  1, 80, 82, 73, 86, 65, 84, 69,  1, 65, 84, 84, 82, 73,\n",
              "         66, 85, 84, 69, 83, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95],\n",
              "        [45, 69, 84, 72, 79, 68, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95]])"
            ]
          },
          "execution_count": 190,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "eng_tokenized# now we have token every word so here 95 is a apdding token u can check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2FFd3zlLb-s",
        "outputId": "9313dde1-eb00-4b8e-dad8-a5f80f5e8789"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  0,  37,  78,   1,  78,  71,  72,   1,  54,  83,  78,  90,   1,  67,\n",
              "          95,  73,  82,  67,  95,  62,   1,  47,  83,  72,  82,   1,  49,  72,\n",
              "          82,   1,  79,  93,  13,   1,  39,  78,  47,  84,   1,  75,  83,  70,\n",
              "          83,  66,  95,  66,   1,  75,  83,  65,  83,  72,  93,  33,   1,   9,\n",
              "          71,  90,  63,  59,  10,   1,  71,  90,  33,   1,  75,  83,  52,  73,\n",
              "          61,   1,  47,  73,  90,  33, 108, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107],\n",
              "        [  0,  66,  83,  54,  84,   1,  49,  85,  61,  93,  33,   1,  47,  93,\n",
              "           1,  53,  83,  67,  82,  43,  33, 108, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107],\n",
              "        [  0,  75,  83,  65,  83, 108, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107]])"
            ]
          },
          "execution_count": 191,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hn_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR87ApeDGKll",
        "outputId": "371d62cc-187f-4c81-9ab0-1fb32b8e8762"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'<padding>': 95}"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{i:j for i,j in english_to_index.items() if j==95}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UphGydFrGUSR",
        "outputId": "b71bbaa2-9817-4b32-d774-c67a9c9c9e40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  0,  37,  78,   1,  78,  71,  72,   1,  54,  83,  78,  90,   1,  67,\n",
              "          95,  73,  82,  67,  95,  62,   1,  47,  83,  72,  82,   1,  49,  72,\n",
              "          82,   1,  79,  93,  13,   1,  39,  78,  47,  84,   1,  75,  83,  70,\n",
              "          83,  66,  95,  66,   1,  75,  83,  65,  83,  72,  93,  33,   1,   9,\n",
              "          71,  90,  63,  59,  10,   1,  71,  90,  33,   1,  75,  83,  52,  73,\n",
              "          61,   1,  47,  73,  90,  33, 108, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107],\n",
              "        [  0,  66,  83,  54,  84,   1,  49,  85,  61,  93,  33,   1,  47,  93,\n",
              "           1,  53,  83,  67,  82,  43,  33, 108, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107],\n",
              "        [  0,  75,  83,  65,  83, 108, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "         107, 107, 107, 107]])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hn_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjtiTfw5GzRt",
        "outputId": "05de846d-668b-401d-e7d9-9d25f00b107d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'<padding>': 107}"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{i:j for i,j in hindi_to_index.items() if j==107}#above is for just batch of 3 sample sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWZjrDm8G4L4"
      },
      "outputs": [],
      "source": [
        "NEG_INFTY = -1e9\n",
        "\n",
        "def create_masks(eng_batch, kn_batch):\n",
        "    num_sentences = len(eng_batch)\n",
        "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
        "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
        "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "\n",
        "    for idx in range(num_sentences):\n",
        "      eng_sentence_length, kn_sentence_length = len(eng_batch[idx]), len(kn_batch[idx])\n",
        "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
        "      kn_chars_to_padding_mask = np.arange(kn_sentence_length + 1, max_sequence_length)\n",
        "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
        "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_self_attention[idx, :, kn_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_self_attention[idx, kn_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_cross_attention[idx, kn_chars_to_padding_mask, :] = True\n",
        "\n",
        "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
        "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
        "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
        "    print(f\"encoder_self_attention_mask {encoder_self_attention_mask.size()}: {encoder_self_attention_mask[0, :10, :10]}\")\n",
        "    print(f\"decoder_self_attention_mask {decoder_self_attention_mask.size()}: {decoder_self_attention_mask[0, :10, :10]}\")\n",
        "    print(f\"decoder_cross_attention_mask {decoder_cross_attention_mask.size()}: {decoder_cross_attention_mask[0, :10, :10]}\")\n",
        "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKRDQBOzIcGh",
        "outputId": "4050e1fe-91c1-42e0-8ea7-bcafce56f73f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Browse the various methods of the current accessible',\n",
              "  'Hide private attributes',\n",
              "  'Method'),\n",
              " ('इस समय जिसे प्राप्त किया गया हो, उसकी विभिन्न विधियों (मेथड) में विचरण करें',\n",
              "  'निजी गुणों को छिपाएं',\n",
              "  'विधि')]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESU0mCARIgM3",
        "outputId": "4bc3e4fc-311c-4f0f-e426-ff78a36753e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Browse the various methods of the current accessible',\n",
              " 'Hide private attributes',\n",
              " 'Method')"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZbJZQMlHSOk",
        "outputId": "b62b9f18-908f-43e8-a77c-5d52a2b6290e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoder_self_attention_mask torch.Size([3, 200, 200]): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "decoder_self_attention_mask torch.Size([3, 200, 200]): tensor([[ 0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
            "decoder_cross_attention_mask torch.Size([3, 200, 200]): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]]]),\n",
              " tensor([[[ 0.0000e+00, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]]]),\n",
              " tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]]]))"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#masking ofor deocder\n",
        "\n",
        "create_masks(batch[0], batch[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9lghjoDHON7"
      },
      "outputs": [],
      "source": [
        "def get_device():\n",
        "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "class SentenceEmbedding(nn.Module):\n",
        "    \"For a given sentence, create an embedding\"\n",
        "    def __init__(self, max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN):\n",
        "        super().__init__()\n",
        "        self.vocab_size = len(language_to_index)\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.embedding = nn.Embedding(self.vocab_size, d_model)\n",
        "        self.language_to_index = language_to_index\n",
        "        self.position_encoder = RoPEEmbedding(d_model)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.START_TOKEN = START_TOKEN\n",
        "        self.END_TOKEN = END_TOKEN\n",
        "        self.PADDING_TOKEN = PADDING_TOKEN\n",
        "\n",
        "    def batch_tokenize(self, batch, start_token=True, end_token=True):\n",
        "\n",
        "        def tokenize(sentence, start_token=True, end_token=True):\n",
        "            sentence_word_indicies = [self.language_to_index[token] for token in list(sentence)]\n",
        "            if start_token:\n",
        "                sentence_word_indicies.insert(0, self.language_to_index[self.START_TOKEN])\n",
        "            if end_token:\n",
        "                sentence_word_indicies.append(self.language_to_index[self.END_TOKEN])\n",
        "            for _ in range(len(sentence_word_indicies), self.max_sequence_length):\n",
        "                sentence_word_indicies.append(self.language_to_index[self.PADDING_TOKEN])\n",
        "\n",
        "            return torch.tensor(sentence_word_indicies, device=x.device)\n",
        "\n",
        "        tokenized = []\n",
        "        for sentence_num in range(len(batch)):\n",
        "           tokenized.append( tokenize(batch[sentence_num], start_token, end_token) )\n",
        "        tokenized = torch.stack(tokenized).to(x.device)\n",
        "        print('tokenized',tokenized)\n",
        "        return tokenized\n",
        "\n",
        "    def forward(self, x, start_token=False,end_token=True): # sentence\n",
        "        x = self.batch_tokenize(x ,end_token)\n",
        "        x = self.embedding(x)\n",
        "        pos = self.position_encoder(x)\n",
        "        x = self.dropout(x + pos)\n",
        "        return x\n",
        "\n",
        "class RoPEEmbedding(torch.nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super().__init__()\n",
        "        assert embedding_dim % 2 == 0, \"Embedding dimension must be even for RoPE\"\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass for Rotary Position Embedding.\n",
        "\n",
        "        Args:\n",
        "        - x: Tensor of shape (batch_size, seq_len, embedding_dim)\n",
        "\n",
        "        Returns:\n",
        "        - Tensor with RoPE applied to the last two dimensions.\n",
        "        \"\"\"\n",
        "        seq_len = x.shape[1]\n",
        "\n",
        "        # Generate position indices\n",
        "        position_ids = torch.arange(seq_len, dtype=torch.float32, device=x.device)\n",
        "\n",
        "        # Compute the rotary angles\n",
        "        freqs = 1.0 / (10000 ** (torch.arange(0, self.embedding_dim, 2, dtype=torch.float32, device=x.device) / self.embedding_dim))\n",
        "        angles = torch.einsum('i,j->ij', position_ids, freqs)\n",
        "\n",
        "        # Create the rotation matrix for sin and cos embeddings\n",
        "        sin = torch.sin(angles).repeat_interleave(2, dim=-1)\n",
        "        cos = torch.cos(angles).repeat_interleave(2, dim=-1)\n",
        "\n",
        "        # Apply rotation using cos and sin embeddings\n",
        "        x1 = x * cos + self.rotate_half(x) * sin\n",
        "        return x1\n",
        "    def rotate_half(self,x):\n",
        "          \"\"\"\n",
        "          Rotate the last dimension by swapping adjacent components and negating the correct ones.\n",
        "          \"\"\"\n",
        "          x1 = x[..., ::2]  # Elements at even positions: x1, x3, x5\n",
        "          x2 = x[..., 1::2]  # Elements at odd positions: x2, x4, x6\n",
        "          return torch.flatten(torch.stack([-x2, x1], dim=-1), start_dim=-2)  # Interleave and negate correctly\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtrAH9Rv9xvU",
        "outputId": "a17ac71d-7cd1-4a72-a513-1e53692e7c2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Browse the various methods of the current accessible',\n",
              "  'Hide private attributes',\n",
              "  'Method'),\n",
              " ('इस समय जिसे प्राप्त किया गया हो, उसकी विभिन्न विधियों (मेथड) में विचरण करें',\n",
              "  'निजी गुणों को छिपाएं',\n",
              "  'विधि')]"
            ]
          },
          "execution_count": 193,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arc39YGxRfZz",
        "outputId": "911aeac3-0877-4b67-9058-238f2418a5d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'<start>': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '#': 4,\n",
              " '$': 5,\n",
              " '%': 6,\n",
              " '&': 7,\n",
              " \"'\": 8,\n",
              " '(': 9,\n",
              " ')': 10,\n",
              " '*': 11,\n",
              " '+': 12,\n",
              " ',': 13,\n",
              " '-': 14,\n",
              " '.': 15,\n",
              " '/': 16,\n",
              " '0': 17,\n",
              " '1': 18,\n",
              " '2': 19,\n",
              " '3': 20,\n",
              " '4': 21,\n",
              " '5': 22,\n",
              " '6': 23,\n",
              " '7': 24,\n",
              " '8': 25,\n",
              " '9': 26,\n",
              " ':': 27,\n",
              " '<': 28,\n",
              " '=': 29,\n",
              " '>': 30,\n",
              " '?': 31,\n",
              " '@': 32,\n",
              " 'A': 33,\n",
              " 'B': 34,\n",
              " 'C': 35,\n",
              " 'D': 36,\n",
              " 'E': 37,\n",
              " 'F': 38,\n",
              " 'G': 39,\n",
              " 'H': 40,\n",
              " 'I': 41,\n",
              " 'J': 42,\n",
              " 'K': 43,\n",
              " 'L': 44,\n",
              " 'M': 45,\n",
              " 'N': 46,\n",
              " 'O': 47,\n",
              " 'P': 48,\n",
              " 'Q': 49,\n",
              " 'R': 50,\n",
              " 'S': 51,\n",
              " 'T': 52,\n",
              " 'U': 53,\n",
              " 'V': 54,\n",
              " 'W': 55,\n",
              " 'X': 56,\n",
              " 'Y': 57,\n",
              " 'Z': 58,\n",
              " '[': 59,\n",
              " '\\\\': 60,\n",
              " ']': 61,\n",
              " '^': 62,\n",
              " '_': 63,\n",
              " '`': 64,\n",
              " 'a': 65,\n",
              " 'b': 66,\n",
              " 'c': 67,\n",
              " 'd': 68,\n",
              " 'e': 69,\n",
              " 'f': 70,\n",
              " 'g': 71,\n",
              " 'h': 72,\n",
              " 'i': 73,\n",
              " 'j': 74,\n",
              " 'k': 75,\n",
              " 'l': 76,\n",
              " 'm': 77,\n",
              " 'n': 78,\n",
              " 'o': 79,\n",
              " 'p': 80,\n",
              " 'q': 81,\n",
              " 'r': 82,\n",
              " 's': 83,\n",
              " 't': 84,\n",
              " 'u': 85,\n",
              " 'v': 86,\n",
              " 'w': 87,\n",
              " 'x': 88,\n",
              " 'y': 89,\n",
              " 'z': 90,\n",
              " '{': 91,\n",
              " '|': 92,\n",
              " '}': 93,\n",
              " '~': 94,\n",
              " '<padding>': 95,\n",
              " '<end>': 96}"
            ]
          },
          "execution_count": 194,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "english_to_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usTim2BkHmwZ",
        "outputId": "73df9f58-2a4a-4a81-9f8e-7749e7922b28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "execution_count": 195,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(batch[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bf4mEzDaH2I9",
        "outputId": "38d7c826-c358-4133-dbb8-befc0e9a746b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Browse the various methods of the current accessible'"
            ]
          },
          "execution_count": 196,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiWozxF7MIuk"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxf1oXSJMJH0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7XwKXMhL7nI",
        "outputId": "46c18a2b-47c3-4080-8f34-63ae5735e0e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([  0,  37,  78,   1,  78,  71,  72,   1,  54,  83,  78,  90,   1,  67,\n",
              "         95,  73,  82,  67,  95,  62,   1,  47,  83,  72,  82,   1,  49,  72,\n",
              "         82,   1,  79,  93,  13,   1,  39,  78,  47,  84,   1,  75,  83,  70,\n",
              "         83,  66,  95,  66,   1,  75,  83,  65,  83,  72,  93,  33,   1,   9,\n",
              "         71,  90,  63,  59,  10,   1,  71,  90,  33,   1,  75,  83,  52,  73,\n",
              "         61,   1,  47,  73,  90,  33, 108, 107, 107, 107, 107, 107, 107, 107,\n",
              "        107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
              "        107, 107])"
            ]
          },
          "execution_count": 202,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenize(batch[1][0],hindi_to_index,start_token=True,end_token=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpmDy2YEMJ7Y",
        "outputId": "dbabdd27-a639-45ef-e157-30da1417b068"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'<start>': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '#': 4,\n",
              " '$': 5,\n",
              " '%': 6,\n",
              " '&': 7,\n",
              " \"'\": 8,\n",
              " '(': 9,\n",
              " ')': 10,\n",
              " '*': 11,\n",
              " '+': 12,\n",
              " ',': 13,\n",
              " '-': 14,\n",
              " '.': 15,\n",
              " '/': 16,\n",
              " '0': 17,\n",
              " '1': 18,\n",
              " '2': 19,\n",
              " '3': 20,\n",
              " '4': 21,\n",
              " '5': 22,\n",
              " '6': 23,\n",
              " '7': 24,\n",
              " '8': 25,\n",
              " '9': 26,\n",
              " ':': 27,\n",
              " '<': 28,\n",
              " '=': 29,\n",
              " '>': 30,\n",
              " '?': 31,\n",
              " 'ँ': 32,\n",
              " 'ं': 33,\n",
              " 'ः': 34,\n",
              " 'अ': 35,\n",
              " 'आ': 36,\n",
              " 'इ': 37,\n",
              " 'ई': 38,\n",
              " 'उ': 39,\n",
              " 'ऊ': 40,\n",
              " 'ऋ': 41,\n",
              " 'ऌ': 42,\n",
              " 'ए': 43,\n",
              " 'ऐ': 44,\n",
              " 'ओ': 45,\n",
              " 'औ': 46,\n",
              " 'क': 47,\n",
              " 'ख': 48,\n",
              " 'ग': 49,\n",
              " 'घ': 50,\n",
              " 'ङ': 51,\n",
              " 'च': 52,\n",
              " 'छ': 53,\n",
              " 'ज': 54,\n",
              " 'झ': 55,\n",
              " 'ञ': 56,\n",
              " 'ट': 57,\n",
              " 'ठ': 58,\n",
              " 'ड': 59,\n",
              " 'ढ': 60,\n",
              " 'ण': 61,\n",
              " 'त': 62,\n",
              " 'थ': 63,\n",
              " 'द': 64,\n",
              " 'ध': 65,\n",
              " 'न': 66,\n",
              " 'प': 67,\n",
              " 'फ': 68,\n",
              " 'ब': 69,\n",
              " 'भ': 70,\n",
              " 'म': 71,\n",
              " 'य': 72,\n",
              " 'र': 73,\n",
              " 'ल': 74,\n",
              " 'व': 75,\n",
              " 'श': 76,\n",
              " 'ष': 77,\n",
              " 'स': 78,\n",
              " 'ह': 79,\n",
              " '़': 80,\n",
              " 'ऽ': 81,\n",
              " 'ा': 82,\n",
              " 'ि': 83,\n",
              " 'ी': 84,\n",
              " 'ु': 85,\n",
              " 'ू': 86,\n",
              " 'ृ': 87,\n",
              " 'ॄ': 88,\n",
              " 'ॅ': 89,\n",
              " 'े': 90,\n",
              " 'ै': 91,\n",
              " 'ॉ': 92,\n",
              " 'ो': 93,\n",
              " 'ौ': 94,\n",
              " '्': 95,\n",
              " 'ॐ': 96,\n",
              " '०': 97,\n",
              " '१': 98,\n",
              " '२': 99,\n",
              " '३': 100,\n",
              " '४': 101,\n",
              " '५': 102,\n",
              " '६': 103,\n",
              " '७': 104,\n",
              " '८': 105,\n",
              " '९': 106,\n",
              " '<padding>': 107,\n",
              " '<end>': 108}"
            ]
          },
          "execution_count": 203,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hindi_to_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o9YHY8rI2uV",
        "outputId": "06f751d4-b82a-4539-cc48-8bc9f013fa26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokenized tensor([[  0,  37,  78,   1,  78,  71,  72,   1,  54,  83,  78,  90,   1,  67,\n",
            "          95,  73,  82,  67,  95,  62,   1,  47,  83,  72,  82,   1,  49,  72,\n",
            "          82,   1,  79,  93,  13,   1,  39,  78,  47,  84,   1,  75,  83,  70,\n",
            "          83,  66,  95,  66,   1,  75,  83,  65,  83,  72,  93,  33,   1,   9,\n",
            "          71,  90,  63,  59,  10,   1,  71,  90,  33,   1,  75,  83,  52,  73,\n",
            "          61,   1,  47,  73,  90,  33, 108, 107, 107, 107, 107, 107, 107, 107,\n",
            "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
            "         107, 107],\n",
            "        [  0,  66,  83,  54,  84,   1,  49,  85,  61,  93,  33,   1,  47,  93,\n",
            "           1,  53,  83,  67,  82,  43,  33, 108, 107, 107, 107, 107, 107, 107,\n",
            "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
            "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
            "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
            "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
            "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
            "         107, 107],\n",
            "        [  0,  75,  83,  65,  83, 108, 107, 107, 107, 107, 107, 107, 107, 107,\n",
            "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
            "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
            "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
            "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
            "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
            "         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
            "         107, 107]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 100, 2])"
            ]
          },
          "execution_count": 207,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d_model = 2\n",
        "max_sequence_length = 100\n",
        "hn_vocab_size = len(hindi_vocabulary)\n",
        "eng_vocab_size = len(english_vocabulary)\n",
        "engtokenization=SentenceEmbedding(max_sequence_length, d_model, hindi_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "t1=engtokenization(batch[1],start_token=True,end_token=True)\n",
        "t1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zGmbG4CGuap"
      },
      "outputs": [],
      "source": [
        "#see in above each sentence is encoded by 200 token 3 batch so 3,200 eahc token 2 dim so 3,200,2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRI9AuidMwIi"
      },
      "outputs": [],
      "source": [
        "#test sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ygk7Kqb9rUY",
        "outputId": "592dfe72-14c6-43bc-ad16-3133f7b46253"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-0.0000e+00, -0.0000e+00],\n",
              "         [ 3.6776e-01, -1.5366e+00],\n",
              "         [-5.8199e-02,  2.1279e-01],\n",
              "         [ 5.6764e-02, -1.3904e-01],\n",
              "         [ 1.5382e-01,  5.0668e-02],\n",
              "         [-1.5258e+00, -1.8942e+00],\n",
              "         [-9.3235e-01, -3.5708e-01],\n",
              "         [-4.5978e-01, -1.2244e+00],\n",
              "         [ 4.1604e-01,  2.9574e+00],\n",
              "         [-5.9714e-01, -1.5521e-01],\n",
              "         [-2.0421e-01,  2.0034e-01],\n",
              "         [-9.8733e-01, -6.9212e-02],\n",
              "         [-1.7813e+00, -7.5952e-02],\n",
              "         [ 2.5517e+00,  1.7287e+00],\n",
              "         [ 4.9911e-03,  3.0778e-01],\n",
              "         [ 3.5298e-01,  1.1101e+00],\n",
              "         [-1.7555e-01,  2.5419e-01],\n",
              "         [ 1.1416e+00, -9.6630e-01],\n",
              "         [-1.2312e+00, -2.4771e+00],\n",
              "         [-8.3439e-01, -1.1151e+00],\n",
              "         [ 6.5675e-01,  2.3415e+00],\n",
              "         [ 5.6464e-03, -4.7954e-01],\n",
              "         [ 1.1032e-02, -1.6947e-02],\n",
              "         [ 0.0000e+00,  1.1678e+00],\n",
              "         [-1.7812e+00,  1.9309e-01],\n",
              "         [-1.4836e+00, -2.5043e+00],\n",
              "         [ 1.0656e+00, -2.5406e+00],\n",
              "         [ 1.7808e-01, -8.1158e-01],\n",
              "         [ 9.1659e-02, -0.0000e+00],\n",
              "         [-6.3630e-01,  1.6473e+00],\n",
              "         [-1.0498e+00, -1.5353e-01],\n",
              "         [ 4.1766e+00,  1.5943e+00],\n",
              "         [-1.9285e+00,  2.0342e+00],\n",
              "         [-1.8990e-01, -6.8243e-01],\n",
              "         [ 2.0881e-01, -3.2263e-01],\n",
              "         [ 1.8691e-01, -4.8284e-01],\n",
              "         [ 1.3283e+00, -9.6278e-01],\n",
              "         [ 3.3880e-01,  1.7993e-01],\n",
              "         [ 2.2211e-01,  3.3710e-01],\n",
              "         [-3.2212e-01, -0.0000e+00],\n",
              "         [-2.3068e-01,  7.6158e-01],\n",
              "         [ 2.2066e-01, -2.8889e-01],\n",
              "         [-7.5771e-01,  1.0522e-01],\n",
              "         [ 2.7654e+00, -3.1247e-01],\n",
              "         [ 2.3304e+00,  3.6879e-01],\n",
              "         [ 1.6316e+00,  1.2584e+00],\n",
              "         [-2.9323e-02, -0.0000e+00],\n",
              "         [ 1.8704e-01, -1.8471e-02],\n",
              "         [-1.1854e+00, -5.0335e-01],\n",
              "         [ 2.2569e+00, -1.5001e+00],\n",
              "         [-2.9125e+00, -3.1135e+00],\n",
              "         [ 1.1577e+00, -4.2983e-01],\n",
              "         [-1.2718e-01, -6.3989e-01],\n",
              "         [-3.5862e-01,  0.0000e+00],\n",
              "         [-1.9243e-01,  1.8574e-02],\n",
              "         [-4.3503e-01, -1.8587e-01],\n",
              "         [-3.9408e-01, -5.0047e-01],\n",
              "         [-1.0723e-01, -6.3600e-01],\n",
              "         [ 1.6180e-01, -4.6784e-01],\n",
              "         [ 1.6566e-01, -1.5060e-01],\n",
              "         [-9.9203e-02,  2.4048e-02],\n",
              "         [-3.8927e-01, -0.0000e+00],\n",
              "         [-4.3786e-01, -4.1798e-01],\n",
              "         [-2.0029e-01, -6.2826e-01],\n",
              "         [ 1.0501e-01, -5.4197e-01],\n",
              "         [ 1.9735e-01, -2.3844e-01],\n",
              "         [-8.1610e-03,  3.2540e-03],\n",
              "         [-3.2258e-01, -0.0000e+00],\n",
              "         [-4.5683e-01, -3.2654e-01],\n",
              "         [-2.8749e-01, -5.9482e-01],\n",
              "         [ 2.9763e-02, -5.9728e-01],\n",
              "         [ 2.0324e-01, -3.3164e-01],\n",
              "         [ 0.0000e+00, -4.2150e-02],\n",
              "         [-2.4028e-01,  5.0483e-03],\n",
              "         [-4.4951e-01, -2.3344e-01],\n",
              "         [-3.6187e-01, -0.0000e+00],\n",
              "         [-5.7940e-02, -6.2936e-01],\n",
              "         [ 1.8285e-01, -4.2278e-01],\n",
              "         [ 0.0000e+00, -1.0855e-01],\n",
              "         [-1.4893e-01,  2.4432e-02],\n",
              "         [-4.1646e-01, -1.4610e-01],\n",
              "         [-4.1751e-01, -4.6336e-01],\n",
              "         [-1.5111e-01, -0.0000e+00],\n",
              "         [ 1.3780e-01, -5.0458e-01],\n",
              "         [ 1.8361e-01, -1.9065e-01],\n",
              "         [-5.5803e-02,  1.7518e-02],\n",
              "         [-3.6033e-01, -7.1471e-02],\n",
              "         [-4.4998e-01, -3.7580e-01],\n",
              "         [-2.4234e-01, -6.1567e-01],\n",
              "         [ 7.1699e-02, -0.0000e+00],\n",
              "         [ 2.0340e-01, -2.8191e-01],\n",
              "         [ 0.0000e+00, -1.5142e-02],\n",
              "         [-2.8557e-01, -1.5498e-02],\n",
              "         [-4.5669e-01, -2.8265e-01],\n",
              "         [-3.2434e-01, -5.7099e-01],\n",
              "         [-1.0205e-02, -6.1541e-01],\n",
              "         [ 1.9690e-01, -3.7507e-01],\n",
              "         [ 0.0000e+00, -7.0947e-02],\n",
              "         [-1.9816e-01,  1.7359e-02],\n",
              "         [-4.3711e-01, -1.9134e-01]],\n",
              "\n",
              "        [[-9.1013e-01, -2.7538e-01],\n",
              "         [-6.6024e-01,  4.0611e-02],\n",
              "         [ 9.0954e-01,  1.5715e+00],\n",
              "         [ 1.7707e-01, -1.0596e-01],\n",
              "         [-3.3806e-01,  2.4869e-01],\n",
              "         [-1.0940e+00, -2.3497e-01],\n",
              "         [-5.3876e+00,  3.0866e+00],\n",
              "         [ 1.3991e-01,  3.5584e-01],\n",
              "         [ 0.0000e+00,  0.0000e+00],\n",
              "         [ 4.4295e-02, -0.0000e+00],\n",
              "         [ 5.5330e-01, -7.0381e-01],\n",
              "         [ 3.1664e+00, -6.7674e-01],\n",
              "         [-9.4409e-01, -0.0000e+00],\n",
              "         [-6.5488e-01, -1.1964e+00],\n",
              "         [ 1.0889e+00,  2.1156e+00],\n",
              "         [-3.4353e-01,  0.0000e+00],\n",
              "         [ 4.3767e-01, -5.0038e-01],\n",
              "         [ 2.4487e-01, -2.1361e-02],\n",
              "         [ 2.8450e+00, -1.1319e+00],\n",
              "         [-0.0000e+00, -3.6698e+00],\n",
              "         [ 1.4560e+00,  1.4919e+00],\n",
              "         [-1.6725e-01,  2.1663e+00],\n",
              "         [-2.1857e-03,  3.8914e-03],\n",
              "         [-0.0000e+00, -6.6182e-01],\n",
              "         [ 3.3484e+00,  3.3018e-01],\n",
              "         [-2.9258e-01, -0.0000e+00],\n",
              "         [ 2.4577e-02, -6.0000e-01],\n",
              "         [ 2.0273e-01, -3.3748e-01],\n",
              "         [ 7.8078e-02, -4.5732e-02],\n",
              "         [-2.3477e-01,  7.0118e-03],\n",
              "         [-4.4818e-01, -2.2774e-01],\n",
              "         [-3.6595e-01, -5.3416e-01],\n",
              "         [-6.3680e-02, -6.3052e-01],\n",
              "         [ 1.8073e-01, -4.2824e-01],\n",
              "         [ 1.4256e-01, -1.1328e-01],\n",
              "         [-0.0000e+00,  2.4775e-02],\n",
              "         [-4.1359e-01, -1.4100e-01],\n",
              "         [-4.2026e-01, -4.5818e-01],\n",
              "         [-0.0000e+00, -6.3517e-01],\n",
              "         [ 1.3424e-01, -5.0923e-01],\n",
              "         [ 1.8560e-01, -1.9616e-01],\n",
              "         [-5.0092e-02,  0.0000e+00],\n",
              "         [-3.5614e-01, -0.0000e+00],\n",
              "         [-0.0000e+00, -3.7006e-01],\n",
              "         [-2.4780e-01, -6.1357e-01],\n",
              "         [ 6.6979e-02, -5.7401e-01],\n",
              "         [ 2.0377e-01, -2.8776e-01],\n",
              "         [ 3.6805e-02, -1.7990e-02],\n",
              "         [-2.8041e-01, -1.2729e-02],\n",
              "         [-4.5623e-01, -2.7682e-01],\n",
              "         [-3.2900e-01, -5.6745e-01],\n",
              "         [-1.5706e-02, -6.1742e-01],\n",
              "         [ 1.9562e-01, -3.8079e-01],\n",
              "         [ 1.1068e-01, -7.5111e-02],\n",
              "         [-1.9243e-01,  1.8574e-02],\n",
              "         [-4.3503e-01, -1.8587e-01],\n",
              "         [-3.9408e-01, -0.0000e+00],\n",
              "         [-0.0000e+00, -0.0000e+00],\n",
              "         [ 1.6180e-01, -4.6784e-01],\n",
              "         [ 1.6566e-01, -0.0000e+00],\n",
              "         [-9.9203e-02,  2.4048e-02],\n",
              "         [-3.8927e-01, -0.0000e+00],\n",
              "         [-4.3786e-01, -4.1798e-01],\n",
              "         [-2.0029e-01, -6.2826e-01],\n",
              "         [ 1.0501e-01, -5.4197e-01],\n",
              "         [ 1.9735e-01, -2.3844e-01],\n",
              "         [-8.1610e-03,  3.2540e-03],\n",
              "         [-3.2258e-01, -3.9089e-02],\n",
              "         [-4.5683e-01, -3.2654e-01],\n",
              "         [-2.8749e-01, -5.9482e-01],\n",
              "         [ 2.9763e-02, -5.9728e-01],\n",
              "         [ 2.0324e-01, -3.3164e-01],\n",
              "         [ 7.3444e-02, -4.2150e-02],\n",
              "         [-2.4028e-01,  5.0483e-03],\n",
              "         [-4.4951e-01, -0.0000e+00],\n",
              "         [-3.6187e-01, -5.3836e-01],\n",
              "         [-5.7940e-02, -6.2936e-01],\n",
              "         [ 1.8285e-01, -0.0000e+00],\n",
              "         [ 1.3911e-01, -1.0855e-01],\n",
              "         [-0.0000e+00,  2.4432e-02],\n",
              "         [-4.1646e-01, -0.0000e+00],\n",
              "         [-4.1751e-01, -4.6336e-01],\n",
              "         [-1.5111e-01, -6.3566e-01],\n",
              "         [ 1.3780e-01, -5.0458e-01],\n",
              "         [ 1.8361e-01, -1.9065e-01],\n",
              "         [-5.5803e-02,  1.7518e-02],\n",
              "         [-3.6033e-01, -7.1471e-02],\n",
              "         [-4.4998e-01, -3.7580e-01],\n",
              "         [-2.4234e-01, -6.1567e-01],\n",
              "         [ 7.1699e-02, -5.7055e-01],\n",
              "         [ 2.0340e-01, -2.8191e-01],\n",
              "         [ 3.1686e-02, -1.5142e-02],\n",
              "         [-2.8557e-01, -0.0000e+00],\n",
              "         [-4.5669e-01, -2.8265e-01],\n",
              "         [-3.2434e-01, -5.7099e-01],\n",
              "         [-1.0205e-02, -6.1541e-01],\n",
              "         [ 1.9690e-01, -3.7507e-01],\n",
              "         [ 1.0656e-01, -7.0947e-02],\n",
              "         [-1.9816e-01,  1.7359e-02],\n",
              "         [-4.3711e-01, -1.9134e-01]],\n",
              "\n",
              "        [[-0.0000e+00, -2.7538e-01],\n",
              "         [ 2.4258e-01,  4.7127e-01],\n",
              "         [-3.4549e-02, -5.4379e-01],\n",
              "         [-1.5547e-01,  2.8335e-01],\n",
              "         [ 0.0000e+00,  9.5100e-01],\n",
              "         [-1.6725e+00,  3.0988e-01],\n",
              "         [-1.6545e+00, -2.3671e+00],\n",
              "         [ 1.9444e+00,  3.1876e+00],\n",
              "         [ 1.9424e-01, -3.8648e-01],\n",
              "         [ 1.1473e-01, -7.9348e-02],\n",
              "         [-1.8668e-01,  1.9689e-02],\n",
              "         [-4.3286e-01, -1.8043e-01],\n",
              "         [-3.9749e-01, -4.9571e-01],\n",
              "         [-1.1308e-01, -6.3629e-01],\n",
              "         [ 1.5889e-01, -4.7292e-01],\n",
              "         [ 1.6836e-01, -1.5580e-01],\n",
              "         [-9.3370e-02,  2.3511e-02],\n",
              "         [-3.8567e-01, -9.9845e-02],\n",
              "         [-4.3979e-01, -0.0000e+00],\n",
              "         [-2.0599e-01, -6.2690e-01],\n",
              "         [ 1.0079e-01, -0.0000e+00],\n",
              "         [ 1.9849e-01, -2.4419e-01],\n",
              "         [-2.7107e-03,  1.1087e-03],\n",
              "         [-3.1783e-01, -3.5661e-02],\n",
              "         [-4.5715e-01, -3.2069e-01],\n",
              "         [-2.9258e-01, -5.9193e-01],\n",
              "         [ 2.4577e-02, -6.0000e-01],\n",
              "         [ 2.0273e-01, -3.3748e-01],\n",
              "         [ 7.8078e-02, -4.5732e-02],\n",
              "         [-2.3477e-01,  7.0118e-03],\n",
              "         [-4.4818e-01, -2.2774e-01],\n",
              "         [-3.6595e-01, -5.3416e-01],\n",
              "         [-6.3680e-02, -6.3052e-01],\n",
              "         [ 1.8073e-01, -4.2824e-01],\n",
              "         [ 1.4256e-01, -0.0000e+00],\n",
              "         [-1.4309e-01,  2.4775e-02],\n",
              "         [-4.1359e-01, -1.4100e-01],\n",
              "         [-4.2026e-01, -4.5818e-01],\n",
              "         [-1.5695e-01, -6.3517e-01],\n",
              "         [ 1.3424e-01, -5.0923e-01],\n",
              "         [ 1.8560e-01, -1.9616e-01],\n",
              "         [-5.0092e-02,  1.6214e-02],\n",
              "         [-3.5614e-01, -6.7370e-02],\n",
              "         [-4.5117e-01, -3.7006e-01],\n",
              "         [-2.4780e-01, -6.1357e-01],\n",
              "         [ 6.6979e-02, -0.0000e+00],\n",
              "         [ 2.0377e-01, -2.8776e-01],\n",
              "         [ 3.6805e-02, -1.7990e-02],\n",
              "         [-0.0000e+00, -1.2729e-02],\n",
              "         [-4.5623e-01, -2.7682e-01],\n",
              "         [-3.2900e-01, -5.6745e-01],\n",
              "         [-1.5706e-02, -6.1742e-01],\n",
              "         [ 1.9562e-01, -3.8079e-01],\n",
              "         [ 1.1068e-01, -7.5111e-02],\n",
              "         [-0.0000e+00,  1.8574e-02],\n",
              "         [-4.3503e-01, -1.8587e-01],\n",
              "         [-3.9408e-01, -5.0047e-01],\n",
              "         [-1.0723e-01, -6.3600e-01],\n",
              "         [ 1.6180e-01, -0.0000e+00],\n",
              "         [ 1.6566e-01, -1.5060e-01],\n",
              "         [-9.9203e-02,  2.4048e-02],\n",
              "         [-0.0000e+00, -1.0446e-01],\n",
              "         [-4.3786e-01, -4.1798e-01],\n",
              "         [-2.0029e-01, -6.2826e-01],\n",
              "         [ 1.0501e-01, -5.4197e-01],\n",
              "         [ 1.9735e-01, -2.3844e-01],\n",
              "         [-8.1610e-03,  0.0000e+00],\n",
              "         [-3.2258e-01, -3.9089e-02],\n",
              "         [-4.5683e-01, -3.2654e-01],\n",
              "         [-2.8749e-01, -5.9482e-01],\n",
              "         [ 2.9763e-02, -5.9728e-01],\n",
              "         [ 2.0324e-01, -3.3164e-01],\n",
              "         [ 7.3444e-02, -4.2150e-02],\n",
              "         [-2.4028e-01,  0.0000e+00],\n",
              "         [-4.4951e-01, -2.3344e-01],\n",
              "         [-0.0000e+00, -5.3836e-01],\n",
              "         [-5.7940e-02, -6.2936e-01],\n",
              "         [ 1.8285e-01, -4.2278e-01],\n",
              "         [ 1.3911e-01, -1.0855e-01],\n",
              "         [-1.4893e-01,  2.4432e-02],\n",
              "         [-4.1646e-01, -1.4610e-01],\n",
              "         [-4.1751e-01, -4.6336e-01],\n",
              "         [-1.5111e-01, -6.3566e-01],\n",
              "         [ 1.3780e-01, -5.0458e-01],\n",
              "         [ 1.8361e-01, -1.9065e-01],\n",
              "         [-5.5803e-02,  1.7518e-02],\n",
              "         [-3.6033e-01, -7.1471e-02],\n",
              "         [-4.4998e-01, -3.7580e-01],\n",
              "         [-2.4234e-01, -6.1567e-01],\n",
              "         [ 7.1699e-02, -0.0000e+00],\n",
              "         [ 2.0340e-01, -2.8191e-01],\n",
              "         [ 3.1686e-02, -1.5142e-02],\n",
              "         [-0.0000e+00, -1.5498e-02],\n",
              "         [-4.5669e-01, -0.0000e+00],\n",
              "         [-0.0000e+00, -5.7099e-01],\n",
              "         [-1.0205e-02, -6.1541e-01],\n",
              "         [ 1.9690e-01, -3.7507e-01],\n",
              "         [ 1.0656e-01, -7.0947e-02],\n",
              "         [-1.9816e-01,  1.7359e-02],\n",
              "         [-4.3711e-01, -1.9134e-01]]], grad_fn=<MulBackward0>)"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t1# bathc of 3 sentenses this is for english so eahc sentence has 200 char and eahc char has 2 dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l7jMwZwBuew",
        "outputId": "7e596b49-df93-4443-c91c-94fdacad62f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 200])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eng_tokenized.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBrigW1RB3R3",
        "outputId": "5101599f-6219-4d4d-a89e-19487635acf4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(eng_tokenized[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOl7a6d3_io_",
        "outputId": "fe8a7c13-902c-4cc1-fe81-860862d51952"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[34, 82, 79, 87, 83, 69,  1, 84, 72, 69,  1, 86, 65, 82, 73, 79, 85, 83,\n",
              "          1, 77, 69, 84, 72, 79, 68, 83,  1, 79, 70,  1, 84, 72, 69,  1, 67, 85,\n",
              "         82, 82, 69, 78, 84,  1, 65, 67, 67, 69, 83, 83, 73, 66, 76, 69, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95],\n",
              "        [40, 73, 68, 69,  1, 80, 82, 73, 86, 65, 84, 69,  1, 65, 84, 84, 82, 73,\n",
              "         66, 85, 84, 69, 83, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95],\n",
              "        [45, 69, 84, 72, 79, 68, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95]])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eng_tokenized#for 1st batch 3 eng sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxbNUBBgLaJc"
      },
      "outputs": [],
      "source": [
        "# above was character embedding now we try for wordise embeding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0GkUpkcOFm7",
        "outputId": "498b8833-09e6-46e4-b3ae-82feb27aa65d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence_word_indices [1, 2, 3, 4, 5, 2, 6, 7]\n",
            "sentence_word_indices [8, 9, 10]\n",
            "sentence_word_indices [11]\n",
            "Tokenized Sentences (Word Indices):\n",
            " [tensor([1, 2, 3, 4, 5, 2, 6, 7]), tensor([ 8,  9, 10]), tensor([11])]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#def batch_tokenize(batch):\n",
        "def tokenize(sentence):\n",
        "  words = sentence.split()  # ✅ Now splits by words\n",
        "  # for below The .get() method of a dictionary tries to find the token in language_to_index.If token exists in the dictionary, it returns the corresponding index.If token does not exist in the dictionary, it returns language_to_index[PADDING_TOKEN],\n",
        "  sentence_word_indices = [language_to_index.get(token, language_to_index[PADDING_TOKEN]) for token in words]\n",
        "  print('sentence_word_indices',sentence_word_indices)\n",
        "  return torch.tensor(sentence_word_indices)\n",
        "\n",
        "\n",
        "# === Special Tokens ===\n",
        "START_TOKEN = \"<START>\"\n",
        "END_TOKEN = \"<END>\"\n",
        "PADDING_TOKEN = \"<PAD>\"\n",
        "\n",
        "# === Define Example Vocabulary ===\n",
        "language_to_index = {\n",
        "    \"Browse\": 1, \"the\": 2, \"various\": 3, \"methods\": 4, \"of\": 5, \"current\": 6, \"accessible\": 7,\n",
        "    \"Hide\": 8, \"private\": 9, \"attributes\": 10, \"Method\": 11,\n",
        "    START_TOKEN: 12, END_TOKEN: 13, PADDING_TOKEN: 0  # Special tokens\n",
        "}\n",
        "\n",
        "batch = [\n",
        "    \"Browse the various methods of the current accessible\",\n",
        "    \"Hide private attributes\",\n",
        "    \"Method\"\n",
        "]\n",
        "\n",
        "tokenized_sentences = [tokenize(sentence) for sentence in batch]\n",
        "print(\"Tokenized Sentences (Word Indices):\\n\", tokenized_sentences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "Mfxoe5o2OFqf",
        "outputId": "ce1df82c-2909-422a-91f8-4415edaf1a4d"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "stack expects each tensor to be equal size, but got [8] at entry 0 and [3] at entry 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-154-3842b930a1c5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [8] at entry 0 and [3] at entry 1"
          ]
        }
      ],
      "source": [
        "torch.stack(tokenized_sentences)# u get his error cuz size of all tensor shud be same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q974swveOFt1",
        "outputId": "9c9d08ef-20cd-4c15-cc02-026dd4647dea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence_word_indices [1, 2, 3, 4, 5, 2, 6, 7]\n",
            "after truncation\n",
            "sentence_word_indices [1, 2, 3]\n",
            "after padding\n",
            "sentence_word_indices [1, 2, 3]\n",
            "sentence_word_indices [8, 9, 10, 5, 0]\n",
            "after truncation\n",
            "sentence_word_indices [8, 9, 10]\n",
            "after padding\n",
            "sentence_word_indices [8, 9, 10]\n",
            "sentence_word_indices [11, 0]\n",
            "after truncation\n",
            "sentence_word_indices [11, 0]\n",
            "after padding\n",
            "sentence_word_indices [11, 0, 0]\n",
            "Tokenized Sentences (Word Indices):\n",
            " tensor([[ 1,  2,  3],\n",
            "        [ 8,  9, 10],\n",
            "        [11,  0,  0]])\n"
          ]
        }
      ],
      "source": [
        "# so we make it same using truncation\n",
        "\n",
        "def batch_tokenize(batch,max_seq_length,start,end):\n",
        "  def tokenize(sentence):\n",
        "    words = sentence.split()  # ✅ Now splits by words\n",
        "    # for below The .get() method of a dictionary tries to find the token in language_to_index.If token exists in the dictionary, it returns the corresponding index.If token does not exist in the dictionary, it returns language_to_index[PADDING_TOKEN],\n",
        "    sentence_word_indices = [language_to_index.get(token, language_to_index[PADDING_TOKEN]) for token in words]\n",
        "    print('sentence_word_indices',sentence_word_indices)\n",
        "    # ✅ Apply truncation BEFORE adding special tokens\n",
        "    print('after truncation')\n",
        "    sentence_word_indices = sentence_word_indices[:max_seq_length - (1 if start else 0) - (1 if end else 0)]\n",
        "    print('sentence_word_indices',sentence_word_indices)\n",
        "    # Apply padding if needed (padding should be added after truncation in case after trunction needs padding)\n",
        "    if len(sentence_word_indices) < max_seq_length:\n",
        "        padding_length = max_seq_length - len(sentence_word_indices)\n",
        "        sentence_word_indices.extend([language_to_index[PADDING_TOKEN]] * padding_length)\n",
        "\n",
        "    print('after padding')\n",
        "    print('sentence_word_indices',sentence_word_indices)\n",
        "    return torch.tensor(sentence_word_indices)\n",
        "\n",
        "  return torch.stack([tokenize(sentence) for sentence in batch])\n",
        "\n",
        "# === Special Tokens ===\n",
        "START_TOKEN = \"<START>\"\n",
        "END_TOKEN = \"<END>\"\n",
        "PADDING_TOKEN = \"<PAD>\"\n",
        "\n",
        "# === Define Example Vocabulary ===\n",
        "language_to_index = {\n",
        "    \"Browse\": 1, \"the\": 2, \"various\": 3, \"methods\": 4, \"of\": 5, \"current\": 6, \"accessible\": 7,\n",
        "    \"Hide\": 8, \"private\": 9, \"attributes\": 10, \"Method\": 11,\n",
        "    START_TOKEN: 12, END_TOKEN: 13, PADDING_TOKEN: 0  # Special tokens\n",
        "}\n",
        "\n",
        "batch = [\n",
        "    \"Browse the various methods of the current accessible\",\n",
        "    \"Hide private attributes of them\",\n",
        "    \"Method acting\"\n",
        "]\n",
        "maxtoken=3\n",
        "\n",
        "\n",
        "tokenized_sentences = batch_tokenize(batch,maxtoken,start=False,end=False)\n",
        "print(\"Tokenized Sentences (Word Indices):\\n\", tokenized_sentences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEV1PPMCOFx-",
        "outputId": "5f083e70-0751-4781-be00-47e96985a7e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "language_to_index.get('Method','not found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdKAZS1ZOF17",
        "outputId": "27ab19b1-2a71-434f-f0f5-933684aa797b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "language_to_index {'Browse': 1, 'the': 2, 'various': 3, 'methods': 4, 'of': 5, 'current': 6, 'accessible': 7, 'Hide': 8, 'private': 9, 'attributes': 10, 'Method': 11, '<START>': 12, '<END>': 13, '<PAD>': 0}\n",
            "sentence_word_indices [1, 2, 3, 4, 5, 2, 6, 7]\n",
            "after truncation\n",
            "sentence_word_indices [1, 2]\n",
            "after start [12, 1, 2]\n",
            "after padding\n",
            "sentence_word_indices [12, 1, 2]\n",
            "sentence_word_indices [8, 9, 10, 5, 0]\n",
            "after truncation\n",
            "sentence_word_indices [8, 9]\n",
            "after start [12, 8, 9]\n",
            "after padding\n",
            "sentence_word_indices [12, 8, 9]\n",
            "sentence_word_indices [11, 0]\n",
            "after truncation\n",
            "sentence_word_indices [11, 0]\n",
            "after start [12, 11, 0]\n",
            "after padding\n",
            "sentence_word_indices [12, 11, 0]\n",
            "Tokenized Sentences (Word Indices):\n",
            " tensor([[12,  1,  2],\n",
            "        [12,  8,  9],\n",
            "        [12, 11,  0]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "# now add start and end token\n",
        "\n",
        "# so we make it same using truncation\n",
        "\n",
        "def batch_tokenize(batch,max_seq_length,language_to_index,start,end):\n",
        "  def tokenize(sentence):\n",
        "    words = sentence.split()  # ✅ Now splits by words\n",
        "    # for below The .get() method of a dictionary tries to find the token in language_to_index.If token exists in the dictionary, it returns the corresponding index.If token does not exist in the dictionary, it returns language_to_index[PADDING_TOKEN],\n",
        "    sentence_word_indices = [language_to_index.get(token, language_to_index[PADDING_TOKEN]) for token in words]\n",
        "    print('sentence_word_indices',sentence_word_indices)\n",
        "    # ✅ Apply truncation BEFORE adding special tokens\n",
        "    print('after truncation')\n",
        "    sentence_word_indices = sentence_word_indices[:max_seq_length - (1 if start else 0) - (1 if end else 0)]\n",
        "    print('sentence_word_indices',sentence_word_indices)\n",
        "\n",
        "    # ✅ Add special tokens\n",
        "    if start:\n",
        "        sentence_word_indices.insert(0, language_to_index[START_TOKEN])\n",
        "        print('after start',sentence_word_indices)\n",
        "    if end:\n",
        "        sentence_word_indices.append(language_to_index[END_TOKEN])\n",
        "        print('after end',sentence_word_indices)\n",
        "\n",
        "    # Apply padding if needed (padding should be added after truncation in case after trunction needs padding)\n",
        "    if len(sentence_word_indices) < max_seq_length:\n",
        "        padding_length = max_seq_length - len(sentence_word_indices)\n",
        "        sentence_word_indices.extend([language_to_index[PADDING_TOKEN]] * padding_length)\n",
        "\n",
        "    print('after padding')\n",
        "    print('sentence_word_indices',sentence_word_indices)\n",
        "    return torch.tensor(sentence_word_indices)\n",
        "\n",
        "  return torch.stack([tokenize(sentence) for sentence in batch])\n",
        "\n",
        "# === Special Tokens ===\n",
        "START_TOKEN = \"<START>\"\n",
        "END_TOKEN = \"<END>\"\n",
        "PADDING_TOKEN = \"<PAD>\"\n",
        "\n",
        "# === Define Example Vocabulary ===\n",
        "language_to_index = {\n",
        "    \"Browse\": 1, \"the\": 2, \"various\": 3, \"methods\": 4, \"of\": 5, \"current\": 6, \"accessible\": 7,\n",
        "    \"Hide\": 8, \"private\": 9, \"attributes\": 10, \"Method\": 11,\n",
        "    START_TOKEN: 12, END_TOKEN: 13, PADDING_TOKEN: 0  # Special tokens\n",
        "}\n",
        "print('language_to_index',language_to_index)\n",
        "batch = [\n",
        "    \"Browse the various methods of the current accessible\",\n",
        "    \"Hide private attributes of them\",\n",
        "    \"Method acting\"\n",
        "]\n",
        "maxtoken=3\n",
        "\n",
        "\n",
        "tokenized_sentences = batch_tokenize(batch,maxtoken,language_to_index=language_to_index,start=True,end=False)\n",
        "print(\"Tokenized Sentences (Word Indices):\\n\", tokenized_sentences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnQlqYZFOF5f",
        "outputId": "f7776278-4c55-410e-d5eb-ecef2c9bb8bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "language_to_index {'Browse': 1, 'the': 2, 'various': 3, 'methods': 4, 'of': 5, 'current': 6, 'accessible': 7, 'Hide': 8, 'private': 9, 'attributes': 10, 'Method': 11, '<START>': 12, '<END>': 13, '<PAD>': 0}\n",
            "sentence_word_indices [1, 2, 3, 4, 5, 2, 6, 7]\n",
            "after truncation\n",
            "sentence_word_indices [1, 2, 3]\n",
            "after start [12, 1, 2, 3]\n",
            "after end [12, 1, 2, 3, 13]\n",
            "after padding\n",
            "sentence_word_indices [12, 1, 2, 3, 13]\n",
            "sentence_word_indices [8, 9, 10, 5, 0]\n",
            "after truncation\n",
            "sentence_word_indices [8, 9, 10]\n",
            "after start [12, 8, 9, 10]\n",
            "after end [12, 8, 9, 10, 13]\n",
            "after padding\n",
            "sentence_word_indices [12, 8, 9, 10, 13]\n",
            "sentence_word_indices [11, 0]\n",
            "after truncation\n",
            "sentence_word_indices [11, 0]\n",
            "after start [12, 11, 0]\n",
            "after end [12, 11, 0, 13]\n",
            "after padding\n",
            "sentence_word_indices [12, 11, 0, 13, 0]\n",
            "Tokenized Sentences (Word Indices):\n",
            " tensor([[12,  1,  2,  3, 13],\n",
            "        [12,  8,  9, 10, 13],\n",
            "        [12, 11,  0, 13,  0]])\n"
          ]
        }
      ],
      "source": [
        "#max len 5\n",
        "import torch\n",
        "import torch.nn\n",
        "\n",
        "\n",
        "def batch_tokenize(batch,max_seq_length,language_to_index,start,end):\n",
        "  def tokenize(sentence):\n",
        "    words = sentence.split()  # ✅ Now splits by words\n",
        "    # for below The .get() method of a dictionary tries to find the token in language_to_index.If token exists in the dictionary, it returns the corresponding index.If token does not exist in the dictionary, it returns language_to_index[PADDING_TOKEN],\n",
        "    sentence_word_indices = [language_to_index.get(token, language_to_index[PADDING_TOKEN]) for token in words]\n",
        "    print('sentence_word_indices',sentence_word_indices)\n",
        "    # ✅ Apply truncation BEFORE adding special tokens\n",
        "    print('after truncation')\n",
        "    sentence_word_indices = sentence_word_indices[:max_seq_length - (1 if start else 0) - (1 if end else 0)]\n",
        "    print('sentence_word_indices',sentence_word_indices)\n",
        "\n",
        "    # ✅ Add special tokens\n",
        "    if start:\n",
        "        sentence_word_indices.insert(0, language_to_index[START_TOKEN])\n",
        "        print('after start',sentence_word_indices)\n",
        "    if end:\n",
        "        sentence_word_indices.append(language_to_index[END_TOKEN])\n",
        "        print('after end',sentence_word_indices)\n",
        "\n",
        "    # Apply padding if needed (padding should be added after truncation in case after trunction needs padding)\n",
        "    if len(sentence_word_indices) < max_seq_length:\n",
        "        padding_length = max_seq_length - len(sentence_word_indices)\n",
        "        sentence_word_indices.extend([language_to_index[PADDING_TOKEN]] * padding_length)\n",
        "\n",
        "    print('after padding')\n",
        "    print('sentence_word_indices',sentence_word_indices)\n",
        "    return torch.tensor(sentence_word_indices)\n",
        "\n",
        "  return torch.stack([tokenize(sentence) for sentence in batch])\n",
        "\n",
        "# === Special Tokens ===\n",
        "START_TOKEN = \"<START>\"\n",
        "END_TOKEN = \"<END>\"\n",
        "PADDING_TOKEN = \"<PAD>\"\n",
        "\n",
        "# === Define Example Vocabulary ===\n",
        "language_to_index = {\n",
        "    \"Browse\": 1, \"the\": 2, \"various\": 3, \"methods\": 4, \"of\": 5, \"current\": 6, \"accessible\": 7,\n",
        "    \"Hide\": 8, \"private\": 9, \"attributes\": 10, \"Method\": 11,\n",
        "    START_TOKEN: 12, END_TOKEN: 13, PADDING_TOKEN: 0  # Special tokens\n",
        "}\n",
        "print('language_to_index',language_to_index)\n",
        "batch = [\n",
        "    \"Browse the various methods of the current accessible\",\n",
        "    \"Hide private attributes of them\",\n",
        "    \"Method acting\"\n",
        "]\n",
        "maxtoken=5\n",
        "\n",
        "\n",
        "tokenized_sentences = batch_tokenize(batch,maxtoken,language_to_index=language_to_index,start=True,end=True)\n",
        "print(\"Tokenized Sentences (Word Indices):\\n\", tokenized_sentences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p--SmJ1aOF8v",
        "outputId": "32787c7d-7e76-4437-d6d6-127bfb793c53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence_word_indices [1, 2, 3, 4, 5, 2, 6, 7]\n",
            "after truncation\n",
            "sentence_word_indices [1, 2, 3]\n",
            "after start [12, 1, 2, 3]\n",
            "after end [12, 1, 2, 3, 13]\n",
            "after padding\n",
            "sentence_word_indices [12, 1, 2, 3, 13]\n",
            "sentence_word_indices [8, 9, 10]\n",
            "after truncation\n",
            "sentence_word_indices [8, 9, 10]\n",
            "after start [12, 8, 9, 10]\n",
            "after end [12, 8, 9, 10, 13]\n",
            "after padding\n",
            "sentence_word_indices [12, 8, 9, 10, 13]\n",
            "sentence_word_indices [11]\n",
            "after truncation\n",
            "sentence_word_indices [11]\n",
            "after start [12, 11]\n",
            "after end [12, 11, 13]\n",
            "after padding\n",
            "sentence_word_indices [12, 11, 13, 0, 0]\n",
            "sentence_word_indices [1, 2, 3, 4, 5, 6, 0, 0, 8, 9, 0, 10, 11, 12]\n",
            "after truncation\n",
            "sentence_word_indices [1, 2, 3]\n",
            "after start [18, 1, 2, 3]\n",
            "after end [18, 1, 2, 3, 19]\n",
            "after padding\n",
            "sentence_word_indices [18, 1, 2, 3, 19]\n",
            "sentence_word_indices [13, 14, 15, 16]\n",
            "after truncation\n",
            "sentence_word_indices [13, 14, 15]\n",
            "after start [18, 13, 14, 15]\n",
            "after end [18, 13, 14, 15, 19]\n",
            "after padding\n",
            "sentence_word_indices [18, 13, 14, 15, 19]\n",
            "sentence_word_indices [17]\n",
            "after truncation\n",
            "sentence_word_indices [17]\n",
            "after start [18, 17]\n",
            "after end [18, 17, 19]\n",
            "after padding\n",
            "sentence_word_indices [18, 17, 19, 0, 0]\n",
            "English Tokenized:\n",
            " tensor([[12,  1,  2,  3, 13],\n",
            "        [12,  8,  9, 10, 13],\n",
            "        [12, 11, 13,  0,  0]])\n",
            "Hindi Tokenized:\n",
            " tensor([[18,  1,  2,  3, 19],\n",
            "        [18, 13, 14, 15, 19],\n",
            "        [18, 17, 19,  0,  0]])\n"
          ]
        }
      ],
      "source": [
        "#now for eng to hin\n",
        "\n",
        "# Hindi vocabulary\n",
        "hindi_to_index = {\n",
        "    \"इस\": 1, \"समय\": 2, \"जिसे\": 3, \"प्राप्त\": 4, \"किया\": 5, \"गया\": 6, \"हो\": 7, \"विभिन्न\": 8,\n",
        "    \"विधियों\": 9, \"में\": 10, \"विचरण\": 11, \"करें\": 12, \"निजी\": 13, \"गुणों\": 14, \"को\": 15,\n",
        "    \"छिपाएं\": 16, \"विधि\": 17,\n",
        "    START_TOKEN: 18, END_TOKEN: 19, PADDING_TOKEN: 0  # Special tokens\n",
        "}\n",
        "\n",
        "# === Special Tokens ===\n",
        "START_TOKEN = \"<START>\"\n",
        "END_TOKEN = \"<END>\"\n",
        "PADDING_TOKEN = \"<PAD>\"\n",
        "\n",
        "# === Define Example Vocabulary ===\n",
        "eng_to_index = {\n",
        "    \"Browse\": 1, \"the\": 2, \"various\": 3, \"methods\": 4, \"of\": 5, \"current\": 6, \"accessible\": 7,\n",
        "    \"Hide\": 8, \"private\": 9, \"attributes\": 10, \"Method\": 11,\n",
        "    START_TOKEN: 12, END_TOKEN: 13, PADDING_TOKEN: 0  # Special tokens\n",
        "}\n",
        "\n",
        "\n",
        "# === Example Bilingual Sentences (English ↔ Hindi) ===\n",
        "bilingual_batch = [\n",
        "    (\"Browse the various methods of the current accessible\", \"इस समय जिसे प्राप्त किया गया हो, उसकी विभिन्न विधियों (मेथड) में विचरण करें\"),\n",
        "    (\"Hide private attributes\", \"निजी गुणों को छिपाएं\"),\n",
        "    (\"Method\", \"विधि\")\n",
        "]\n",
        "\n",
        "# === Parameters ===\n",
        "max_seq_length = 5  # ✅ Limit to 5 words per sentence\n",
        "\n",
        "# === Separate English and Hindi Sentences ===\n",
        "english_sentences = [pair[0] for pair in bilingual_batch]\n",
        "hindi_sentences = [pair[1] for pair in bilingual_batch]\n",
        "\n",
        "# === Tokenization ===\n",
        "english_tokenized = batch_tokenize(english_sentences, max_seq_length, eng_to_index,start=True,end=True)\n",
        "hindi_tokenized = batch_tokenize(hindi_sentences, max_seq_length, hindi_to_index,start=True,end=True)\n",
        "\n",
        "print(\"English Tokenized:\\n\", english_tokenized)\n",
        "print(\"Hindi Tokenized:\\n\", hindi_tokenized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmQf9sIxOF_e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhdqtPm5B95r",
        "outputId": "38762880-d05c-46ad-930d-57fee9c64637"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Browse': 1,\n",
              " 'the': 2,\n",
              " 'various': 3,\n",
              " 'methods': 4,\n",
              " 'of': 5,\n",
              " 'current': 6,\n",
              " 'accessible': 7,\n",
              " 'Hide': 8,\n",
              " 'private': 9,\n",
              " 'attributes': 10,\n",
              " 'Method': 11,\n",
              " '<START>': 12,\n",
              " '<END>': 13,\n",
              " '<PAD>': 0}"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "language_to_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cblPKPajJQfa",
        "outputId": "af665d50-42d8-4d6d-fdb4-e8c87f79638a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English Tokenized:\n",
            " tensor([[12,  1,  2,  3, 13],\n",
            "        [12,  8,  9, 10, 13],\n",
            "        [12, 11, 13,  0,  0]])\n",
            "Hindi Tokenized:\n",
            " tensor([[18,  1,  2,  3, 19],\n",
            "        [18, 13, 14, 15, 19],\n",
            "        [18, 17, 19,  0,  0]])\n"
          ]
        }
      ],
      "source": [
        "#max len 5 #final\n",
        "import torch\n",
        "import torch.nn\n",
        "\n",
        "\n",
        "def batch_tokenize(batch,max_seq_length,language_to_index,start,end):\n",
        "  def tokenize(sentence):\n",
        "    words = sentence.split()  # ✅ Now splits by words\n",
        "    # for below The .get() method of a dictionary tries to find the token in language_to_index.If token exists in the dictionary, it returns the corresponding index.If token does not exist in the dictionary, it returns language_to_index[PADDING_TOKEN],\n",
        "    sentence_word_indices = [language_to_index.get(token, language_to_index[PADDING_TOKEN]) for token in words]\n",
        "    # ✅ Apply truncation BEFORE adding special tokens\n",
        "    sentence_word_indices = sentence_word_indices[:max_seq_length - (1 if start else 0) - (1 if end else 0)]\n",
        "\n",
        "    # ✅ Add special tokens\n",
        "    if start:\n",
        "        sentence_word_indices.insert(0, language_to_index[START_TOKEN])\n",
        "\n",
        "    if end:\n",
        "        sentence_word_indices.append(language_to_index[END_TOKEN])\n",
        "\n",
        "\n",
        "    # Apply padding if needed (padding should be added after truncation in case after trunction needs padding)\n",
        "    if len(sentence_word_indices) < max_seq_length:\n",
        "        padding_length = max_seq_length - len(sentence_word_indices)\n",
        "        sentence_word_indices.extend([language_to_index[PADDING_TOKEN]] * padding_length)\n",
        "\n",
        "    return torch.tensor(sentence_word_indices)\n",
        "\n",
        "  return torch.stack([tokenize(sentence) for sentence in batch])\n",
        "\n",
        "# === Special Tokens ===\n",
        "START_TOKEN = \"<START>\"\n",
        "END_TOKEN = \"<END>\"\n",
        "PADDING_TOKEN = \"<PAD>\"\n",
        "eng_to_index = {\n",
        "    \"Browse\": 1, \"the\": 2, \"various\": 3, \"methods\": 4, \"of\": 5, \"current\": 6, \"accessible\": 7,\n",
        "    \"Hide\": 8, \"private\": 9, \"attributes\": 10, \"Method\": 11,\n",
        "    START_TOKEN: 12, END_TOKEN: 13, PADDING_TOKEN: 0  # Special tokens\n",
        "}\n",
        "hindi_to_index = {\n",
        "    \"इस\": 1, \"समय\": 2, \"जिसे\": 3, \"प्राप्त\": 4, \"किया\": 5, \"गया\": 6, \"हो\": 7, \"विभिन्न\": 8,\n",
        "    \"विधियों\": 9, \"में\": 10, \"विचरण\": 11, \"करें\": 12, \"निजी\": 13, \"गुणों\": 14, \"को\": 15,\n",
        "    \"छिपाएं\": 16, \"विधि\": 17,\n",
        "    START_TOKEN: 18, END_TOKEN: 19, PADDING_TOKEN: 0  # Special tokens\n",
        "}\n",
        "\n",
        "# === Example Bilingual Sentences (English ↔ Hindi) ===\n",
        "bilingual_batch = [\n",
        "    (\"Browse the various methods of the current accessible\", \"इस समय जिसे प्राप्त किया गया हो, उसकी विभिन्न विधियों (मेथड) में विचरण करें\"),\n",
        "    (\"Hide private attributes\", \"निजी गुणों को छिपाएं\"),\n",
        "    (\"Method\", \"विधि\")\n",
        "]\n",
        "\n",
        "# === Parameters ===\n",
        "max_seq_length = 5  # ✅ Limit to 5 words per sentence\n",
        "\n",
        "# === Separate English and Hindi Sentences ===\n",
        "english_sentences = [pair[0] for pair in bilingual_batch]\n",
        "hindi_sentences = [pair[1] for pair in bilingual_batch]\n",
        "\n",
        "# === Tokenization ===\n",
        "english_tokenized = batch_tokenize(english_sentences, max_seq_length, eng_to_index,start=True,end=True)\n",
        "hindi_tokenized = batch_tokenize(hindi_sentences, max_seq_length, hindi_to_index,start=True,end=True)\n",
        "\n",
        "print(\"English Tokenized:\\n\", english_tokenized)\n",
        "print(\"Hindi Tokenized:\\n\", hindi_tokenized)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7bfvnTtKQ0c"
      },
      "outputs": [],
      "source": [
        "class SentenceEmbedding(nn.Module):\n",
        "    \"For a given sentence, create an embedding\"\n",
        "    def __init__(self, max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN):\n",
        "        super().__init__()\n",
        "        self.vocab_size = len(language_to_index)\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        # create embedding of dmodel from input tokens\n",
        "        self.embedding = nn.Embedding(self.vocab_size, d_model)\n",
        "        self.language_to_index = language_to_index\n",
        "        self.position_encoder = RoPEEmbedding(d_model)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.START_TOKEN = START_TOKEN\n",
        "        self.END_TOKEN = END_TOKEN\n",
        "        self.PADDING_TOKEN = PADDING_TOKEN\n",
        "\n",
        "    def batch_tokenize(self,batch,start,end):\n",
        "      def tokenize(sentence):\n",
        "        words = sentence.split()  # ✅ Now splits by words\n",
        "        # for below The .get() method of a dictionary tries to find the token in language_to_index.If token exists in the dictionary, it returns the corresponding index.If token does not exist in the dictionary, it returns language_to_index[PADDING_TOKEN],\n",
        "        sentence_word_indices = [self.language_to_index.get(token, self.language_to_index[self.PADDING_TOKEN]) for token in words]\n",
        "        # ✅ Apply truncation BEFORE adding special tokens\n",
        "        sentence_word_indices = sentence_word_indices[:self.max_sequence_length - (1 if start else 0) - (1 if end else 0)]\n",
        "\n",
        "        # ✅ Add special tokens\n",
        "        if start:\n",
        "            sentence_word_indices.insert(0, self.language_to_index[self.START_TOKEN])\n",
        "\n",
        "        if end:\n",
        "            sentence_word_indices.append(self.language_to_index[self.END_TOKEN])\n",
        "\n",
        "\n",
        "        # Apply padding if needed (padding should be added after truncation in case after trunction needs padding)\n",
        "        if len(sentence_word_indices) < self.max_sequence_length:\n",
        "            padding_length = self.max_sequence_length - len(sentence_word_indices)\n",
        "            sentence_word_indices.extend([self.language_to_index[self.PADDING_TOKEN]] * padding_length)\n",
        "\n",
        "        return torch.tensor(sentence_word_indices)\n",
        "\n",
        "      return torch.stack([tokenize(sentence) for sentence in batch])\n",
        "\n",
        "\n",
        "    def forward(self, x,start,end): # sentence\n",
        "        x = self.batch_tokenize(x,start,end)\n",
        "        (print('x',x))\n",
        "        x = self.embedding(x)\n",
        "        pos = self.position_encoder(x)\n",
        "        x = self.dropout(x + pos)\n",
        "        return x\n",
        "\n",
        "\n",
        "#rope embedding\n",
        "class RoPEEmbedding(torch.nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super().__init__()\n",
        "        assert embedding_dim % 2 == 0, \"Embedding dimension must be even for RoPE\"\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass for Rotary Position Embedding.\n",
        "\n",
        "        Args:\n",
        "        - x: Tensor of shape (batch_size, seq_len, embedding_dim)\n",
        "\n",
        "        Returns:\n",
        "        - Tensor with RoPE applied to the last two dimensions.\n",
        "        \"\"\"\n",
        "        seq_len = x.shape[1]\n",
        "\n",
        "        # Generate position indices\n",
        "        position_ids = torch.arange(seq_len, dtype=torch.float32, device=x.device)\n",
        "\n",
        "        # Compute the rotary angles\n",
        "        freqs = 1.0 / (10000 ** (torch.arange(0, self.embedding_dim, 2, dtype=torch.float32, device=x.device) / self.embedding_dim))\n",
        "        angles = torch.einsum('i,j->ij', position_ids, freqs)\n",
        "\n",
        "        # Create the rotation matrix for sin and cos embeddings\n",
        "        sin = torch.sin(angles).repeat_interleave(2, dim=-1)\n",
        "        cos = torch.cos(angles).repeat_interleave(2, dim=-1)\n",
        "\n",
        "        # Apply rotation using cos and sin embeddings\n",
        "        x1 = x * cos + self.rotate_half(x) * sin\n",
        "        return x1\n",
        "\n",
        "\n",
        "    def rotate_half(self,x):\n",
        "        \"\"\"\n",
        "        Rotate the last dimension of the input tensor by swapping odd and even elements and negating one.\n",
        "\n",
        "        Args:\n",
        "        - x: Tensor of shape (..., embedding_dim)\n",
        "\n",
        "        Returns:\n",
        "        - Rotated tensor of the same shape.\n",
        "        \"\"\"\n",
        "        x1, x2 = x[..., ::2], x[..., 1::2]  # Split into even and odd dimensions\n",
        "        return torch.cat((-x2, x1), dim=-1)\n",
        "\n",
        "#sine embedding\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, max_sequence_length):\n",
        "        super().__init__()\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        # Generate the positional encoding\n",
        "        even_i = torch.arange(0, self.d_model, 2).float()\n",
        "        denominator = torch.pow(10000, even_i/self.d_model)\n",
        "        position = torch.arange(self.max_sequence_length).reshape(self.max_sequence_length, 1)\n",
        "        even_PE = torch.sin(position / denominator)\n",
        "        odd_PE = torch.cos(position / denominator)\n",
        "        stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
        "        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
        "\n",
        "        # Ensure the PE matches the batch size and sequence length\n",
        "        PE = PE.unsqueeze(0).expand(batch_size, seq_len, self.d_model)\n",
        "\n",
        "        return PE + x\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuysoSpZKQ3q",
        "outputId": "3319cfac-b742-4f88-8fad-64e93af65782"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hindi_sentences ['इस']\n",
            "x tensor([[18,  1, 19,  0,  0]])\n"
          ]
        }
      ],
      "source": [
        "#testing\n",
        "\n",
        "\n",
        "# === Special Tokens ===\n",
        "START_TOKEN = \"<START>\"\n",
        "END_TOKEN = \"<END>\"\n",
        "PADDING_TOKEN = \"<PAD>\"\n",
        "eng_to_index = {\n",
        "    \"Browse\": 2, \"the\": 1, \"various\": 4, \"methods\": 3, \"of\": 5, \"current\": 7, \"accessible\": 6,\n",
        "    \"Hide\": 11, \"private\": 10, \"attributes\": 12, \"Method\": 9,\n",
        "    START_TOKEN: 12, END_TOKEN: 13, PADDING_TOKEN: 0  # Special tokens\n",
        "}\n",
        "hindi_to_index = {\n",
        "    \"इस\": 1, \"समय\": 2, \"जिसे\": 3, \"प्राप्त\": 4, \"किया\": 5, \"गया\": 6, \"हो\": 7, \"विभिन्न\": 8,\n",
        "    \"विधियों\": 9, \"में\": 10, \"विचरण\": 11, \"करें\": 12, \"निजी\": 13, \"गुणों\": 14, \"को\": 15,\n",
        "    \"छिपाएं\": 16, \"विधि\": 17,\n",
        "    START_TOKEN: 18, END_TOKEN: 19, PADDING_TOKEN: 0  # Special tokens\n",
        "}\n",
        "\n",
        "# === Example Bilingual Sentences (English ↔ Hindi) ===\n",
        "bilingual_batch = [\n",
        "    (\"Browse the various methods of the current accessible\", \"इस समय जिसे प्राप्त किया गया हो, उसकी विभिन्न विधियों (मेथड) में विचरण करें\"),\n",
        "    (\"Hide private attributes\", \"निजी गुणों को छिपाएं\"),\n",
        "    (\"Method\", \"विधि\")\n",
        "]\n",
        "\n",
        "# === Separate English and Hindi Sentences ===\n",
        "english_sentences = [pair[0] for pair in bilingual_batch]\n",
        "hindi_sentences = [pair[1] for pair in bilingual_batch]\n",
        "\n",
        "index_to_hindi = {v: k for k, v in hindi_to_index.items()}\n",
        "\n",
        "# === Parameters ===\n",
        "max_seq_length = 5  # ✅ Limit to 5 words per sentence\n",
        "\n",
        "# === Separate English and Hindi Sentences ===\n",
        "english_sentences = [pair[0] for pair in bilingual_batch]\n",
        "hindi_sentences = [pair[1] for pair in bilingual_batch]\n",
        "\n",
        "d_model = 2\n",
        "batch_size = 3\n",
        "ffn_hidden = 2048\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "num_layers = 1\n",
        "max_sequence_length = 5\n",
        "hn_vocab_size = len(hindi_to_index)\n",
        "eng_vocab_size = len(eng_to_index)\n",
        "torch.manual_seed(2)\n",
        "tokenization=SentenceEmbedding(max_sequence_length, d_model, hindi_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "#engtoken=tokenization(english_sentences,start=True,end=True)\n",
        "#print('engtoken',engtoken)\n",
        "sample='इस'\n",
        "sample.split()\n",
        "print('hindi_sentences',sample.split())\n",
        "hintoken=tokenization(sample.split(),start=True,end=True)\n",
        "\n",
        "#print('hintoken',hintoken)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmruGM4zKQ7g"
      },
      "outputs": [],
      "source": [
        "#below is for char by char embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vtv_sQTJJQiR",
        "outputId": "2440843e-a646-4e53-9f76-e3a7e7e80c57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['इस']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample='इस'\n",
        "sample.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aM9xFiUAJQlI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "1FMFZ8GwJQru"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class SentenceEmbedding(nn.Module):\n",
        "    \"For a given sentence, create an embedding\"\n",
        "    def __init__(self, max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN):\n",
        "        super().__init__()\n",
        "        self.vocab_size = len(language_to_index)\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.embedding = nn.Embedding(self.vocab_size, d_model)\n",
        "        self.language_to_index = language_to_index\n",
        "        self.position_encoder = RoPEEmbedding(d_model)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.START_TOKEN = START_TOKEN\n",
        "        self.END_TOKEN = END_TOKEN\n",
        "        self.PADDING_TOKEN = PADDING_TOKEN\n",
        "\n",
        "    def batch_tokenize(self, batch, start_token=True, end_token=True):\n",
        "      def tokenize(sentence, start_token=True, end_token=True):\n",
        "          # Convert sentence to list of word indices\n",
        "          sentence_word_indices = [self.language_to_index[token] for token in list(sentence)]\n",
        "\n",
        "          # Add start and end tokens if needed\n",
        "          if start_token:\n",
        "              sentence_word_indices.insert(0, self.language_to_index[self.START_TOKEN])\n",
        "          if end_token:\n",
        "              sentence_word_indices.append(self.language_to_index[self.END_TOKEN])\n",
        "\n",
        "          # Pad the sentence to max_sequence_length\n",
        "          while len(sentence_word_indices) < self.max_sequence_length:\n",
        "              sentence_word_indices.append(self.language_to_index[self.PADDING_TOKEN])\n",
        "\n",
        "          # Ensure the sequence length doesn't exceed max_sequence_length\n",
        "          sentence_word_indices = sentence_word_indices[:self.max_sequence_length]\n",
        "\n",
        "          return torch.tensor(sentence_word_indices)\n",
        "\n",
        "      tokenized = []\n",
        "      for sentence_num in range(len(batch)):\n",
        "          tokenized.append(tokenize(batch[sentence_num], start_token, end_token))\n",
        "\n",
        "      # All sentences are now padded to the same length, so stack them\n",
        "      tokenized = torch.stack(tokenized)  # All tensors will have the same size now\n",
        "      return tokenized\n",
        "\n",
        "\n",
        "    def forward(self, x,start_token, end_token=True): # sentence\n",
        "        x = self.batch_tokenize(x ,start_token,end_token)\n",
        "        x = self.embedding(x)\n",
        "        pos = self.position_encoder(x)\n",
        "        x = self.dropout(x + pos)\n",
        "        return x\n",
        "\n",
        "class RoPEEmbedding(torch.nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super().__init__()\n",
        "        assert embedding_dim % 2 == 0, \"Embedding dimension must be even for RoPE\"\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass for Rotary Position Embedding.\n",
        "\n",
        "        Args:\n",
        "        - x: Tensor of shape (batch_size, seq_len, embedding_dim)\n",
        "\n",
        "        Returns:\n",
        "        - Tensor with RoPE applied to the last two dimensions.\n",
        "        \"\"\"\n",
        "        seq_len = x.shape[1]\n",
        "\n",
        "        # Generate position indices\n",
        "        position_ids = torch.arange(seq_len, dtype=torch.float32, device=x.device)\n",
        "\n",
        "        # Compute the rotary angles\n",
        "        freqs = 1.0 / (10000 ** (torch.arange(0, self.embedding_dim, 2, dtype=torch.float32, device=x.device) / self.embedding_dim))\n",
        "        angles = torch.einsum('i,j->ij', position_ids, freqs)\n",
        "\n",
        "        # Create the rotation matrix for sin and cos embeddings\n",
        "        sin = torch.sin(angles).repeat_interleave(2, dim=-1)\n",
        "        cos = torch.cos(angles).repeat_interleave(2, dim=-1)\n",
        "\n",
        "        # Apply rotation using cos and sin embeddings\n",
        "        x1 = x * cos + self.rotate_half(x) * sin\n",
        "        return x1\n",
        "    def rotate_half(self,x):\n",
        "          \"\"\"\n",
        "          Rotate the last dimension by swapping adjacent components and negating the correct ones.\n",
        "          \"\"\"\n",
        "          x1 = x[..., ::2]  # Elements at even positions: x1, x3, x5\n",
        "          x2 = x[..., 1::2]  # Elements at odd positions: x2, x4, x6\n",
        "          return torch.flatten(torch.stack([-x2, x1], dim=-1), start_dim=-2)  # Interleave and negate correctly\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_llBwqYBaE2",
        "outputId": "06c381e5-9251-4a6c-99db-daf6b3ccb447"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "engtoken torch.Size([3, 3, 2])\n"
          ]
        }
      ],
      "source": [
        "#testing\n",
        "\n",
        "\n",
        "# === Special Tokens ===\n",
        "START_TOKEN = \"<START>\"\n",
        "END_TOKEN = \"<END>\"\n",
        "PADDING_TOKEN = \"<PAD>\"\n",
        "\n",
        "START_TOKEN = '<start>'\n",
        "PADDING_TOKEN = '<padding>'\n",
        "END_TOKEN = '<end>'\n",
        "\n",
        "english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "                      '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', '@',\n",
        "                      'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "                      'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
        "                      'Y', 'Z', '[', '\\\\', ']', '^', '_', '`',\n",
        "                      'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "                      'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
        "                      'y', 'z', '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]\n",
        "\n",
        "\n",
        "\n",
        "hindi_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "                    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', 'ँ', 'ं', 'ः',\n",
        "                    'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऌ', 'ए', 'ऐ', 'ओ', 'औ',\n",
        "                    'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण',\n",
        "                    'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श', 'ष', 'स', 'ह',\n",
        "                    '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्', 'ॐ',\n",
        "                    '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', PADDING_TOKEN, END_TOKEN]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "index_to_hindi = {k:v for k,v in enumerate(hindi_vocabulary)}\n",
        "hindi_to_index = {v:k for k,v in enumerate(hindi_vocabulary)}\n",
        "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
        "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}\n",
        "# === Example Bilingual Sentences (English ↔ Hindi) ===\n",
        "\n",
        "\n",
        "# === Separate English and Hindi Sentences ===\n",
        "english_sentences =batch[0]\n",
        "hindi_sentences = batch[1]\n",
        "\n",
        "\n",
        "\n",
        "d_model = 2\n",
        "batch_size = 3\n",
        "ffn_hidden = 2048\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "num_layers = 1\n",
        "max_sequence_length = 3\n",
        "torch.manual_seed(2)\n",
        "engtokenization=SentenceEmbedding(max_sequence_length, d_model, english_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "engtoken=engtokenization(batch[0],start_token=True,end_token=True)\n",
        "print('engtoken',engtoken.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "ZUDWfBH-N9zK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj3_3L4KAd9i",
        "outputId": "f787cf38-b0ef-4cff-c9c8-bb25f6f5e3a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hindi_sentences ['इस', 'निजी गुणों']\n",
            "hintoken torch.Size([2, 3, 2])\n"
          ]
        }
      ],
      "source": [
        "max_sequence_length=3\n",
        "sample=['इस','निजी गुणों']\n",
        "print('hindi_sentences',sample)\n",
        "hintokenization=SentenceEmbedding(max_sequence_length, d_model, hindi_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "hintoken=hintokenization(sample,start_token=True,end_token=True)\n",
        "print('hintoken',hintoken.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R38Lq3HzBJbu",
        "outputId": "159cd21f-d713-46c3-fab8-87251990aa9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 2.0528, -2.7078],\n",
              "         [ 2.1669, -0.7417],\n",
              "         [-1.0729,  1.6896]],\n",
              "\n",
              "        [[ 2.0528, -2.7078],\n",
              "         [-4.9444,  1.3839],\n",
              "         [ 0.0000, -0.0000]]], grad_fn=<MulBackward0>)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hintoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu-whnZRfE93",
        "outputId": "45bb9c19-80b9-4a93-e89e-73309c0e9582"
      },
      "outputs": [],
      "source": [
        "#break into batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VAypHen-gCkk",
        "outputId": "6ca920f0-b11a-4f07-d1e0-3bab2e0fe45a"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Deeplearning\\\\LLMs_from_scratch\\\\hindi_english_parallel.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Read the CSV file\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDeeplearning\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mLLMs_from_scratch\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mhindi_english_parallel.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Check the data\u001b[39;00m\n\u001b[0;32m      9\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
            "File \u001b[1;32mc:\\Users\\AMBAR KUMAR\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\AMBAR KUMAR\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Users\\AMBAR KUMAR\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\AMBAR KUMAR\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Users\\AMBAR KUMAR\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Deeplearning\\\\LLMs_from_scratch\\\\hindi_english_parallel.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('Deeplearning/LLMs from scratch/hindi_english_parallel.csv')\n",
        "\n",
        "# Check the data\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "Z0hVlMDG2DSG",
        "outputId": "08dce228-0990-48bd-885b-e18e2c359e5c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>English</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hindi</th>\n",
              "      <td>312</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "English      2\n",
              "Hindi      312\n",
              "dtype: int64"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HfOScr9n2HEs",
        "outputId": "544229c3-3176-4007-f82f-f418546da17c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "repr_error": "Out of range float values are not JSON compliant: nan",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-286d3f4f-684c-426c-aae9-06f7a613cf3b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-286d3f4f-684c-426c-aae9-06f7a613cf3b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-286d3f4f-684c-426c-aae9-06f7a613cf3b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-286d3f4f-684c-426c-aae9-06f7a613cf3b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-58cada2a-c9b4-4277-9c47-605cd6e7d835\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-58cada2a-c9b4-4277-9c47-605cd6e7d835')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-58cada2a-c9b4-4277-9c47-605cd6e7d835 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  English Hindi\n",
              "0     NaN   NaN\n",
              "1     NaN   NaN\n",
              "2     NaN   NaN\n",
              "3     NaN   NaN\n",
              "4     NaN   NaN"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df.isnull()].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1R0IQmS2Mxc",
        "outputId": "2a6fc77b-1519-4c58-dd55-af557487863d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(130476, 2)"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "L4-z92me2Pgl"
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "t0zd3YHS2R2_",
        "outputId": "3d632c73-736e-4da7-c808-39761ebf9abd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>English</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hindi</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "English    0\n",
              "Hindi      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "fM4xC5I05Ypo"
      },
      "outputs": [],
      "source": [
        "sample=df[:100000].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "swF1550H0RpU"
      },
      "outputs": [],
      "source": [
        "engsen=sample['English'].to_list()\n",
        "hindisen=sample['Hindi'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N9odqw-0TsN",
        "outputId": "2000e784-650f-4946-b663-abfc7c9c9ff4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['Help!',\n",
              "  'Jump.',\n",
              "  'Jump.',\n",
              "  'Jump.',\n",
              "  'Hello!',\n",
              "  'Hello!',\n",
              "  'Cheers!',\n",
              "  'Cheers!',\n",
              "  'Got it?',\n",
              "  \"I'm OK.\"],\n",
              " ['बचाओ!',\n",
              "  'उछलो.',\n",
              "  'कूदो.',\n",
              "  'छलांग.',\n",
              "  'नमस्ते।',\n",
              "  'नमस्कार।',\n",
              "  'वाह-वाह!',\n",
              "  'चियर्स!',\n",
              "  'समझे कि नहीं?',\n",
              "  'मैं ठीक हूँ।'])"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "engsen[:10],hindisen[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "3Kn6NI892g1k"
      },
      "outputs": [],
      "source": [
        "engsen1=engsen[:10000]\n",
        "hindisen1=hindisen[:10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKFJPTGCiOxa",
        "outputId": "b23b27d6-6e02-4200-f69f-cca6400c3e12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sentences: 10000\n",
            "Number of valid sentences: 4966\n"
          ]
        }
      ],
      "source": [
        "\n",
        "max_sequence_length = 200\n",
        "# to check if a token or character/alphabet ins engsen or hindi is present in about hindi/eng vocab pf charceter\n",
        "def is_valid_tokens(sentence, vocab):\n",
        "    for token in list(set(sentence)):\n",
        "        if token not in vocab:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "#to check if engsend or hindisen each sent has max 200 charcers\n",
        "def is_valid_length(sentence, max_sequence_length):\n",
        "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
        "\n",
        "valid_sentence_indicies = []\n",
        "for index in range(len(hindisen1)):\n",
        "    hindi_sentence, english_sentence = hindisen1[index], engsen1[index]\n",
        "    if is_valid_length(hindi_sentence, max_sequence_length) \\\n",
        "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
        "      and is_valid_tokens(hindi_sentence, hindi_vocabulary):\n",
        "        valid_sentence_indicies.append(index)\n",
        "\n",
        "print(f\"Number of sentences: {len(hindisen1)}\")\n",
        "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJqpg4OX5SzN",
        "outputId": "86ae86cf-ca24-4c7c-e135-ef15e15505ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total sentences: 10000\n",
            "Valid sentences: 2700\n"
          ]
        }
      ],
      "source": [
        "max_sequence_length = 200  # Maximum allowed characters\n",
        "min_sequence_length = 40   # Minimum required characters\n",
        "\n",
        "# Function to check if a sentence contains only valid tokens\n",
        "def is_valid_tokens(sentence, vocab):\n",
        "    for token in list(set(sentence)):  # Ensure unique characters are checked\n",
        "        if token not in vocab:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "# Function to check if sentence length is within min & max limits\n",
        "def is_valid_length(sentence, min_length, max_length):\n",
        "    sentence_length = len(sentence)  # No need to convert to list explicitly\n",
        "    return min_length <= sentence_length < max_length  # Ensuring it fits the range\n",
        "\n",
        "valid_sentence_indices = []\n",
        "for index in range(len(hindisen1)):\n",
        "    hindi_sentence, english_sentence = hindisen1[index], engsen1[index]\n",
        "\n",
        "    if (is_valid_length(hindi_sentence, min_sequence_length, max_sequence_length) and\n",
        "        is_valid_length(english_sentence, min_sequence_length, max_sequence_length) and\n",
        "        is_valid_tokens(hindi_sentence, hindi_vocabulary)):\n",
        "\n",
        "        valid_sentence_indices.append(index)\n",
        "\n",
        "print(f\"Total sentences: {len(hindisen1)}\")\n",
        "print(f\"Valid sentences: {len(valid_sentence_indices)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "HWitAguA6K32"
      },
      "outputs": [],
      "source": [
        "hindisen1 = [hindisen1[i] for i in valid_sentence_indices]\n",
        "engsen1 = [engsen1[i] for i in valid_sentence_indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15XF7a706WrU",
        "outputId": "4e6f6361-2bdd-4e0a-f202-53d1ccc21658"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['How much time do we have to finish this?',\n",
              " 'Can you identify the man in this picture?',\n",
              " 'Will you take us for a drive next Sunday?',\n",
              " 'Could you send someone up to make the bed?',\n",
              " 'Do you know the man standing on the bridge?',\n",
              " \"You aren't leaving Japan for good, are you?\",\n",
              " 'Do you know this part of the city very well?',\n",
              " 'If it rains tomorrow, will you stay at home?',\n",
              " 'Are you going to cut down all the trees here?',\n",
              " 'Did it not occur to you to close the windows?']"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "engsen1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fktzWKHJ8Sje",
        "outputId": "97e0f250-1ec9-4115-b30b-0aeaa584b13a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['हमारे पास इस काम को खतम करने के लिए कितना समय है?',\n",
              " 'क्या तुम उस आदमी को उसकी तस्वीर से पहचान सकते हो?',\n",
              " 'हमें अगले हफ़्ते ड्राईव पर लेजाओगे क्या?',\n",
              " 'आप किसी को बिस्तर बनाने के लिए भेज सकते हैं क्या?',\n",
              " 'तुम ब्रिज पर खड़े हुए आदमी को जानते हो क्या?',\n",
              " 'तुम हमेशा के लिए तो जापान नहीं जा रहे हो ना?',\n",
              " 'तुम शहर के इस हिस्से को अच्छी तरह से जानते हो क्या?',\n",
              " 'अगर कल बारिश हुई तो तुम घर में रहोगे क्या?',\n",
              " 'तुम यहाँ सारे के सारे पेड़ काट डालोगे क्या?',\n",
              " 'तुम्हें खिड़कियाँ बंद करने की नहीं सूझी?']"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hindisen1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "w3pQUJj6jL13"
      },
      "outputs": [],
      "source": [
        "#to craeted cuomt dataset pytorch inbuitl method used in our own csutom datas set class\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "\n",
        "    def __init__(self, english_sentences, lang_sentences):\n",
        "        self.english_sentences = english_sentences\n",
        "        self.lang_sentences = lang_sentences\n",
        "    #rturn number of eng/hind or sentences in a list\n",
        "    def __len__(self):\n",
        "        return len(self.english_sentences)\n",
        "    #return 1:1 mapping of one lang to other\n",
        "    def __getitem__(self, idx):\n",
        "        return self.english_sentences[idx], self.lang_sentences[idx]\n",
        "\n",
        "\n",
        "dataset = TextDataset(engsen1, hindisen1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "HzM2nqeo6V_-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpD-gHP53e2Z",
        "outputId": "807b2414-a5a8-47ba-a84d-d1933e8bd713"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('How much time do we have to finish this?',\n",
              " 'हमारे पास इस काम को खतम करने के लिए कितना समय है?')"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.english_sentences[0],dataset.lang_sentences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aurvrZnt3hnQ",
        "outputId": "73b1a17c-4ea1-434f-dbd9-a50b4ddbcae1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('How much time do we have to finish this?',\n",
              " 'हमारे पास इस काम को खतम करने के लिए कितना समय है?')"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_Kxg0lp31h8",
        "outputId": "48bdfd56-85dd-4a23-c7ec-7e408ceeff69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('How much time do we have to finish this?', 'Can you identify the man in this picture?'), ('हमारे पास इस काम को खतम करने के लिए कितना समय है?', 'क्या तुम उस आदमी को उसकी तस्वीर से पहचान सकते हो?')]\n",
            "[('Will you take us for a drive next Sunday?', 'Could you send someone up to make the bed?'), ('हमें अगले हफ़्ते ड्राईव पर लेजाओगे क्या?', 'आप किसी को बिस्तर बनाने के लिए भेज सकते हैं क्या?')]\n",
            "[('Do you know the man standing on the bridge?', \"You aren't leaving Japan for good, are you?\"), ('तुम ब्रिज पर खड़े हुए आदमी को जानते हो क्या?', 'तुम हमेशा के लिए तो जापान नहीं जा रहे हो ना?')]\n"
          ]
        }
      ],
      "source": [
        "#this code will create batches\n",
        "batch_size = 2\n",
        "train_loader = DataLoader(dataset, batch_size)\n",
        "iterator = iter(train_loader)\n",
        "\n",
        "for batch_num, batch in enumerate(iterator):\n",
        "    print(batch)\n",
        "    if batch_num > 1:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-MKpxTm-Tr3",
        "outputId": "90cfcdd5-9227-445f-965a-5e50c2b92cad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Do you know this part of the city very well?',\n",
              "  'If it rains tomorrow, will you stay at home?'),\n",
              " ('तुम शहर के इस हिस्से को अच्छी तरह से जानते हो क्या?',\n",
              "  'अगर कल बारिश हुई तो तुम घर में रहोगे क्या?')]"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "n2c0b3JI-ZYZ"
      },
      "outputs": [],
      "source": [
        "eng_batch, ln_batch = batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvlpTrpK-cS2",
        "outputId": "e50d8a14-3980-457b-d061-6691b932f263"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Do you know this part of the city very well?',\n",
              " 'If it rains tomorrow, will you stay at home?')"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eng_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFlc7wQ7-ehW",
        "outputId": "8b63efb8-ac39-4345-bce5-4ee909b1351a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('तुम शहर के इस हिस्से को अच्छी तरह से जानते हो क्या?',\n",
              " 'अगर कल बारिश हुई तो तुम घर में रहोगे क्या?')"
            ]
          },
          "execution_count": 180,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ln_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUOfWEK68czg",
        "outputId": "63b270ca-7560-4785-ff2c-004378786620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "batch_num 1\n",
            "batch\n",
            "[('How much time do we have to finish this?', 'Can you identify the man in this picture?'), ('हमारे पास इस काम को खतम करने के लिए कितना समय है?', 'क्या तुम उस आदमी को उसकी तस्वीर से पहचान सकते हो?')]\n",
            "engtoken torch.Size([2, 3, 2])\n",
            "hintoken torch.Size([2, 3, 2])\n",
            "\n",
            "batch_num 2\n",
            "batch\n",
            "[('Will you take us for a drive next Sunday?', 'Could you send someone up to make the bed?'), ('हमें अगले हफ़्ते ड्राईव पर लेजाओगे क्या?', 'आप किसी को बिस्तर बनाने के लिए भेज सकते हैं क्या?')]\n",
            "engtoken torch.Size([2, 3, 2])\n",
            "hintoken torch.Size([2, 3, 2])\n",
            "\n",
            "batch_num 3\n",
            "batch\n",
            "[('Do you know the man standing on the bridge?', \"You aren't leaving Japan for good, are you?\"), ('तुम ब्रिज पर खड़े हुए आदमी को जानते हो क्या?', 'तुम हमेशा के लिए तो जापान नहीं जा रहे हो ना?')]\n",
            "engtoken torch.Size([2, 3, 2])\n",
            "hintoken torch.Size([2, 3, 2])\n"
          ]
        }
      ],
      "source": [
        "#now combinig with sentence ebedding\n",
        "batch_size = 2\n",
        "train_loader = DataLoader(dataset, batch_size)\n",
        "iterator = iter(train_loader)\n",
        "d_model = 2\n",
        "ffn_hidden = 2048\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "num_layers = 1\n",
        "max_sequence_length = 3\n",
        "torch.manual_seed(2)\n",
        "engtokenization=SentenceEmbedding(max_sequence_length, d_model, english_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "hintokenization=SentenceEmbedding(max_sequence_length, d_model, hindi_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "\n",
        "\n",
        "for batch_num, batch in enumerate(iterator):\n",
        "    print('\\nbatch_num',batch_num+1)\n",
        "    print('batch')\n",
        "    print(batch)\n",
        "    eng_batch, ln_batch = batch\n",
        "    engtoken=engtokenization(eng_batch,start_token=True,end_token=True)\n",
        "    print('engtoken',engtoken.shape)\n",
        "    hintoken=hintokenization(ln_batch,start_token=True,end_token=True)\n",
        "    print('hintoken',hintoken.shape)\n",
        "    if batch_num > 1:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMXt_MZp-div"
      },
      "outputs": [],
      "source": [
        "#above works perfectly"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
